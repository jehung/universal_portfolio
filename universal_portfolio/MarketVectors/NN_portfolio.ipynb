{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recently published a post about applying [deep learning to the stock market](https://medium.com/@TalPerry/deep-learning-the-stock-market-df853d139e02#.e33ao345g). This Notebook is an initial sketch of the implementation. People approach the market to make money, and I am no exception, so it may come as some suprise that I am giving this away. In fact, I don't think this implementation does make money. But it does illustrate a variety of concepts that are important for data science, deep learning and the application of both to finance. I learnt almost everything I know from tutorials like this one on the internet, and I hope someone will learn a thing or two from this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in this thing?\n",
    "\n",
    "This notebook goes through the full the process of implementing the ideas I layed out in the post. That is it covers\n",
    "* Preparing the data\n",
    "* Building a baseline\n",
    "* Implementing a DL model\n",
    "\n",
    "## A (more or less) standard data science work flow\n",
    "\n",
    "### Defining the problem you want to solve\n",
    "I think all three of those stages are important, and in many respects they are ordered by both importance and the order in which I approach them. My first step in this process was writing that post (4.5K words) explaining in relatively simple terms what I want to do and why. \n",
    "\n",
    "### Collecting data\n",
    "The next stage was collecting data, this actually took me a while and I ended up going with a freely availble dataset you can download [here](https://quantquote.com/historical-stock-data). \n",
    "\n",
    "### Reconciling the problem and the data\n",
    "Once I had an idea of what problem I wanted to solve and I had some data I went about getting the data into a shape  I could work with. \n",
    "\n",
    "### Making a baseline\n",
    "Next I built a baseline model. A baseline doesn't need to be good, but it needs to be something you can compare your actual model to, so that you can know if all the fancy complicated things you did are any better than something simple. This is also a good point to choose how to measure your models performance.\n",
    "\n",
    "### Testing the idea\n",
    "I ended up bulding to baselines. One is a simple logistic regression and the other is a 3 layer feed forward network, or if you like big words, a multi layer perceptron. I made the first because I wanted a baseline and the second because I wanted to see if the additional complexity and computation cost of an RNN added benefit over a simpler network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepaparation\n",
    "Maybe its different for the more fortunate but in my experience 80% of the work in data science is data engineering. If I had to break that down even more it would be 20% \"science\", 20% engineering and 60% finding the right, clean data. \n",
    "For the project at hand I wanted a lot of data for many stocks. My \"production\" version uses slightly different data but for the POC using 10 years of the S&P was enough to prover my point.\n",
    "\n",
    "In case you missed it, the S&P500 is an index of 500 stocks that is updated once every 3 months. For POC purposes using daily data is sufficient and I ended up finding a free data set [here](https://quantquote.com/historical-stock-data). You can download it and point the *datapath* variable to point at it and runs this notebook yourself\n",
    "This notebook explores the data, joins all the stocks and creates targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preliminaries\n",
    "So first we need to import some libraries and define some helper functions\n",
    "* **get_ticker** applies a regex to the filename we are looking at and extracts the ticker from it\n",
    "* **ret calculates** to log return between two points. Returns should be observed in log space because\n",
    "    * Returns are log-normally distributed so log returns are follow a normal distribution\n",
    "    * You can some log returns instead of taking products which makes life easier\n",
    "* **zscore** maps a pandas series to it's zscore. In other words, it makes it have mean 0 and variance 1\n",
    "    * It's good to have variablised normalized like this as it makes all of the dimensions of your data behave the same\n",
    "    * It doesn't make sense to apply a z-score to distributions that don't (more or less) folllow the normal distribution. So check your variables first and if they don't follow a normal distribution transform them so that they do are use other scaling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../util/stock_dfs/'\n",
    "filepath = os.path.join(datapath,os.listdir(datapath)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../util/stock_dfs/.DS_Store \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "ticker_regex = re.compile('.+_(?P<ticker>.+)\\.csv')\n",
    "#get_ticker =lambda x :ticker_regex.match(x).groupdict()['ticker'] -- use my own function to get ticker\n",
    "get_ticker = lambda x:x.split('/')[-1].split('.')[0]\n",
    "print(filepath,get_ticker(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret = lambda x,y: log(y/x) #Log return \n",
    "zscore = lambda x:(x -x.mean())/x.std() # zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First peak at the data\n",
    "I blah blahed alot without actually looking at the data. lets load it. I use the pandas library to rad a single CSV. Since the data had no column headers I specified them. I don't know what the first column is so I labeled it UNK.\n",
    "Notice that the index, which is the real first column in the original data, is a date but in a string pandas didn't understand. We're going to parse it to a datetime object later so that pandas preserves the right order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ec72ce34ac2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1628\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Usecols do not match names.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_noconvert_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_set_noconvert_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1695\u001b[0m                         \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m                     \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_noconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "D = pd.read_csv(filepath, parse_dates=['Date'])\n",
    "D.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>26.230330</td>\n",
       "      <td>26.323318</td>\n",
       "      <td>25.836910</td>\n",
       "      <td>25.965666</td>\n",
       "      <td>24.504511</td>\n",
       "      <td>2598700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>25.965666</td>\n",
       "      <td>26.001431</td>\n",
       "      <td>25.658083</td>\n",
       "      <td>25.708155</td>\n",
       "      <td>24.261494</td>\n",
       "      <td>2789500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>25.450644</td>\n",
       "      <td>25.643776</td>\n",
       "      <td>24.835480</td>\n",
       "      <td>24.871244</td>\n",
       "      <td>23.471676</td>\n",
       "      <td>4939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>25.278971</td>\n",
       "      <td>25.665236</td>\n",
       "      <td>25.071531</td>\n",
       "      <td>25.278971</td>\n",
       "      <td>23.856462</td>\n",
       "      <td>4901100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-08</td>\n",
       "      <td>25.293276</td>\n",
       "      <td>25.572247</td>\n",
       "      <td>25.143061</td>\n",
       "      <td>25.243204</td>\n",
       "      <td>23.822704</td>\n",
       "      <td>5680700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close   Volume\n",
       "0 2008-01-02  26.230330  26.323318  25.836910  25.965666  24.504511  2598700\n",
       "1 2008-01-03  25.965666  26.001431  25.658083  25.708155  24.261494  2789500\n",
       "2 2008-01-04  25.450644  25.643776  24.835480  24.871244  23.471676  4939200\n",
       "3 2008-01-07  25.278971  25.665236  25.071531  25.278971  23.856462  4901100\n",
       "4 2008-01-08  25.293276  25.572247  25.143061  25.243204  23.822704  5680700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.head() #Lets peack at it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Relevant Data\n",
    "We don't care about prices, just about their fluctations. So we'll give the log return of the various prices, and take a zscore so everything is nice. \n",
    "Also, extract the ticker from the file name and add it to the df as a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inputs(filepath):\n",
    "    D = pd.read_csv(filepath).set_index('Date')\n",
    "                                          #,header=None,names=['UNK','o','h','l','c','v']) #Load the dataframe with headers\n",
    "    #D.index = pd.to_datetime(D.index,format='%Y-%m-%d') # Set the indix to a datetime\n",
    "    Res = pd.DataFrame()\n",
    "    ticker = get_ticker(filepath)\n",
    "\n",
    "    Res['c_2_o'] = zscore(ret(D.Open,D.Close))\n",
    "    Res['h_2_o'] = zscore(ret(D.Open,D.High))\n",
    "    Res['l_2_o'] = zscore(ret(D.Open,D.Low))\n",
    "    Res['c_2_h'] = zscore(ret(D.High,D.Close))\n",
    "    Res['h_2_l'] = zscore(ret(D.High,D.Low))\n",
    "    Res['c1_c0'] = ret(D.Close,D.Close.shift(-1)).fillna(0) #Tommorows return \n",
    "    Res['vol'] = zscore(D.Volume)\n",
    "    Res['ticker'] = ticker\n",
    "    return Res\n",
    "#Res = make_inputs(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_2_o</th>\n",
       "      <th>h_2_o</th>\n",
       "      <th>l_2_o</th>\n",
       "      <th>c_2_h</th>\n",
       "      <th>h_2_l</th>\n",
       "      <th>c1_c0</th>\n",
       "      <th>vol</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>-0.603321</td>\n",
       "      <td>-0.708941</td>\n",
       "      <td>-0.208379</td>\n",
       "      <td>-0.155152</td>\n",
       "      <td>0.379177</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>-0.636741</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>-0.593552</td>\n",
       "      <td>-0.882954</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.712638</td>\n",
       "      <td>-0.033096</td>\n",
       "      <td>-0.556092</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-1.325307</td>\n",
       "      <td>-0.385348</td>\n",
       "      <td>-0.925942</td>\n",
       "      <td>-1.493744</td>\n",
       "      <td>-0.453307</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>0.352556</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>-0.035187</td>\n",
       "      <td>0.226634</td>\n",
       "      <td>0.318732</td>\n",
       "      <td>-0.272674</td>\n",
       "      <td>0.083354</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0.336452</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>-0.146201</td>\n",
       "      <td>-0.110993</td>\n",
       "      <td>0.493857</td>\n",
       "      <td>-0.097413</td>\n",
       "      <td>0.486554</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.665978</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               c_2_o     h_2_o     l_2_o     c_2_h     h_2_l     c1_c0  \\\n",
       "Date                                                                     \n",
       "2008-01-02 -0.603321 -0.708941 -0.208379 -0.155152  0.379177 -0.009967   \n",
       "2008-01-03 -0.593552 -0.882954  0.036739  0.029837  0.712638 -0.033096   \n",
       "2008-01-04 -1.325307 -0.385348 -0.925942 -1.493744 -0.453307  0.016261   \n",
       "2008-01-07 -0.035187  0.226634  0.318732 -0.272674  0.083354 -0.001416   \n",
       "2008-01-08 -0.146201 -0.110993  0.493857 -0.097413  0.486554  0.002547   \n",
       "\n",
       "                 vol ticker  \n",
       "Date                         \n",
       "2008-01-02 -0.636741      A  \n",
       "2008-01-03 -0.556092      A  \n",
       "2008-01-04  0.352556      A  \n",
       "2008-01-07  0.336452      A  \n",
       "2008-01-08  0.665978      A  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res.head() # Lets look at what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_2_o</th>\n",
       "      <th>h_2_o</th>\n",
       "      <th>l_2_o</th>\n",
       "      <th>c_2_h</th>\n",
       "      <th>h_2_l</th>\n",
       "      <th>c1_c0</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_2_o</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706641</td>\n",
       "      <td>0.693055</td>\n",
       "      <td>0.717973</td>\n",
       "      <td>0.015871</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.016244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_2_o</th>\n",
       "      <td>0.706641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204337</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>-0.607545</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.339818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_2_o</th>\n",
       "      <td>0.693055</td>\n",
       "      <td>0.204337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778360</td>\n",
       "      <td>0.653382</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>-0.335809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2_h</th>\n",
       "      <td>0.717973</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>0.778360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620098</td>\n",
       "      <td>-0.005933</td>\n",
       "      <td>-0.357249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_2_l</th>\n",
       "      <td>0.015871</td>\n",
       "      <td>-0.607545</td>\n",
       "      <td>0.653382</td>\n",
       "      <td>0.620098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>-0.535274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1_c0</th>\n",
       "      <td>-0.000460</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>-0.005933</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <td>-0.016244</td>\n",
       "      <td>0.339818</td>\n",
       "      <td>-0.335809</td>\n",
       "      <td>-0.357249</td>\n",
       "      <td>-0.535274</td>\n",
       "      <td>0.029548</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          c_2_o     h_2_o     l_2_o     c_2_h     h_2_l     c1_c0       vol\n",
       "c_2_o  1.000000  0.706641  0.693055  0.717973  0.015871 -0.000460 -0.016244\n",
       "h_2_o  0.706641  1.000000  0.204337  0.014828 -0.607545  0.005370  0.339818\n",
       "l_2_o  0.693055  0.204337  1.000000  0.778360  0.653382  0.018008 -0.335809\n",
       "c_2_h  0.717973  0.014828  0.778360  1.000000  0.620098 -0.005933 -0.357249\n",
       "h_2_l  0.015871 -0.607545  0.653382  0.620098  1.000000  0.010459 -0.535274\n",
       "c1_c0 -0.000460  0.005370  0.018008 -0.005933  0.010459  1.000000  0.029548\n",
       "vol   -0.016244  0.339818 -0.335809 -0.357249 -0.535274  0.029548  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res.corr() #Quick check to see we didn't mess it up. All values should be different, otherwise we repeated a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the full data set\n",
    "I'll iterate over each file, run the above and concat to a final df. Then we'll pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final = pd.DataFrame()\n",
    "for f in os.listdir(datapath):\n",
    "    filepath = os.path.join(datapath,f)\n",
    "    if filepath.endswith('.csv'):\n",
    "        Res = make_inputs(filepath)\n",
    "        Final = Final.append(Res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final.head()\n",
    "Final.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_2_o</th>\n",
       "      <th>h_2_o</th>\n",
       "      <th>l_2_o</th>\n",
       "      <th>c_2_h</th>\n",
       "      <th>h_2_l</th>\n",
       "      <th>c1_c0</th>\n",
       "      <th>vol</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>-0.603321</td>\n",
       "      <td>-0.708941</td>\n",
       "      <td>-0.208379</td>\n",
       "      <td>-0.155152</td>\n",
       "      <td>0.379177</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>-0.636741</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>-0.593552</td>\n",
       "      <td>-0.882954</td>\n",
       "      <td>0.036739</td>\n",
       "      <td>0.029837</td>\n",
       "      <td>0.712638</td>\n",
       "      <td>-0.033096</td>\n",
       "      <td>-0.556092</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-1.325307</td>\n",
       "      <td>-0.385348</td>\n",
       "      <td>-0.925942</td>\n",
       "      <td>-1.493744</td>\n",
       "      <td>-0.453307</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>0.352556</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>-0.035187</td>\n",
       "      <td>0.226634</td>\n",
       "      <td>0.318732</td>\n",
       "      <td>-0.272674</td>\n",
       "      <td>0.083354</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0.336452</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>-0.146201</td>\n",
       "      <td>-0.110993</td>\n",
       "      <td>0.493857</td>\n",
       "      <td>-0.097413</td>\n",
       "      <td>0.486554</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.665978</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               c_2_o     h_2_o     l_2_o     c_2_h     h_2_l     c1_c0  \\\n",
       "Date                                                                     \n",
       "2008-01-02 -0.603321 -0.708941 -0.208379 -0.155152  0.379177 -0.009967   \n",
       "2008-01-03 -0.593552 -0.882954  0.036739  0.029837  0.712638 -0.033096   \n",
       "2008-01-04 -1.325307 -0.385348 -0.925942 -1.493744 -0.453307  0.016261   \n",
       "2008-01-07 -0.035187  0.226634  0.318732 -0.272674  0.083354 -0.001416   \n",
       "2008-01-08 -0.146201 -0.110993  0.493857 -0.097413  0.486554  0.002547   \n",
       "\n",
       "                 vol ticker  \n",
       "Date                         \n",
       "2008-01-02 -0.636741      A  \n",
       "2008-01-03 -0.556092      A  \n",
       "2008-01-04  0.352556      A  \n",
       "2008-01-07  0.336452      A  \n",
       "2008-01-08  0.665978      A  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pivot_columns = Final.columns[:-1]\n",
    "P = Final.pivot_table(index=Final.index,columns='ticker',values=pivot_columns) # Make a pivot table from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">c1_c0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>XYL</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>-0.009967</td>\n",
       "      <td>-0.046091</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>-0.017343</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.015262</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871786</td>\n",
       "      <td>-0.393039</td>\n",
       "      <td>0.682807</td>\n",
       "      <td>0.311627</td>\n",
       "      <td>-0.260591</td>\n",
       "      <td>-0.753432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.231260</td>\n",
       "      <td>-0.690485</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>-0.033096</td>\n",
       "      <td>-0.024673</td>\n",
       "      <td>-0.061960</td>\n",
       "      <td>-0.079406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023021</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>-0.034818</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.989941</td>\n",
       "      <td>-0.504889</td>\n",
       "      <td>-0.400928</td>\n",
       "      <td>-0.047999</td>\n",
       "      <td>-0.547116</td>\n",
       "      <td>-0.889366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.142855</td>\n",
       "      <td>-0.857160</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>0.016261</td>\n",
       "      <td>-0.014611</td>\n",
       "      <td>0.044147</td>\n",
       "      <td>-0.013476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013155</td>\n",
       "      <td>-0.027296</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>-0.012783</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365741</td>\n",
       "      <td>-0.536379</td>\n",
       "      <td>0.599084</td>\n",
       "      <td>0.429950</td>\n",
       "      <td>-0.288010</td>\n",
       "      <td>-0.852734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557788</td>\n",
       "      <td>-0.697810</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>-0.001416</td>\n",
       "      <td>-0.105088</td>\n",
       "      <td>-0.052876</td>\n",
       "      <td>-0.036635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025675</td>\n",
       "      <td>-0.033590</td>\n",
       "      <td>-0.018486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540284</td>\n",
       "      <td>-0.271225</td>\n",
       "      <td>0.036374</td>\n",
       "      <td>0.790889</td>\n",
       "      <td>-0.302766</td>\n",
       "      <td>-0.672058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006898</td>\n",
       "      <td>-0.411987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>0.002547</td>\n",
       "      <td>-0.010959</td>\n",
       "      <td>-0.015102</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351571</td>\n",
       "      <td>-0.257501</td>\n",
       "      <td>1.300453</td>\n",
       "      <td>0.175424</td>\n",
       "      <td>0.278874</td>\n",
       "      <td>-0.832352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.827988</td>\n",
       "      <td>-0.153840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2968 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               c1_c0                                                         \\\n",
       "ticker             A       AAL       AAP      AAPL ABBV       ABC       ACN   \n",
       "Date                                                                          \n",
       "2008-01-02 -0.009967 -0.046091  0.009531  0.000462  NaN  0.006042 -0.017343   \n",
       "2008-01-03 -0.033096 -0.024673 -0.061960 -0.079406  NaN -0.023021 -0.015068   \n",
       "2008-01-04  0.016261 -0.014611  0.044147 -0.013476  NaN  0.013155 -0.027296   \n",
       "2008-01-07 -0.001416 -0.105088 -0.052876 -0.036635  NaN  0.028215  0.000000   \n",
       "2008-01-08  0.002547 -0.010959 -0.015102  0.046493  NaN  0.008941 -0.004721   \n",
       "\n",
       "                                         ...       vol                      \\\n",
       "ticker          ADBE       ADI       ADM ...       XEL        XL      XLNX   \n",
       "Date                                     ...                                 \n",
       "2008-01-02  0.001916 -0.015262  0.010331 ... -0.871786 -0.393039  0.682807   \n",
       "2008-01-03 -0.034818 -0.026424  0.002621 ... -0.989941 -0.504889 -0.400928   \n",
       "2008-01-04 -0.002978 -0.012783  0.000218 ... -0.365741 -0.536379  0.599084   \n",
       "2008-01-07 -0.025675 -0.033590 -0.018486 ... -0.540284 -0.271225  0.036374   \n",
       "2008-01-08  0.006101 -0.014123  0.003769 ... -0.351571 -0.257501  1.300453   \n",
       "\n",
       "                                                                      \n",
       "ticker           XOM      XRAY       XRX XYL       ZBH      ZION ZTS  \n",
       "Date                                                                  \n",
       "2008-01-02  0.311627 -0.260591 -0.753432 NaN -0.231260 -0.690485 NaN  \n",
       "2008-01-03 -0.047999 -0.547116 -0.889366 NaN -0.142855 -0.857160 NaN  \n",
       "2008-01-04  0.429950 -0.288010 -0.852734 NaN  0.557788 -0.697810 NaN  \n",
       "2008-01-07  0.790889 -0.302766 -0.672058 NaN  1.006898 -0.411987 NaN  \n",
       "2008-01-08  0.175424  0.278874 -0.832352 NaN  2.827988 -0.153840 NaN  \n",
       "\n",
       "[5 rows x 2968 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening the pivot\n",
    "source http://stackoverflow.com/questions/14507794/python-pandas-how-to-flatten-a-hierarchical-index-in-columns\n",
    "At the end of this P is a flattened dataframe of all the entries for each stock, one day per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c1_c0', 'A'),\n",
       " ('c1_c0', 'AAL'),\n",
       " ('c1_c0', 'AAP'),\n",
       " ('c1_c0', 'AAPL'),\n",
       " ('c1_c0', 'ABBV'),\n",
       " ('c1_c0', 'ABC'),\n",
       " ('c1_c0', 'ACN'),\n",
       " ('c1_c0', 'ADBE'),\n",
       " ('c1_c0', 'ADI'),\n",
       " ('c1_c0', 'ADM'),\n",
       " ('c1_c0', 'ADSK'),\n",
       " ('c1_c0', 'AEE'),\n",
       " ('c1_c0', 'AEP'),\n",
       " ('c1_c0', 'AES'),\n",
       " ('c1_c0', 'AET'),\n",
       " ('c1_c0', 'AFL'),\n",
       " ('c1_c0', 'AGN'),\n",
       " ('c1_c0', 'AIG'),\n",
       " ('c1_c0', 'AIV'),\n",
       " ('c1_c0', 'AIZ'),\n",
       " ('c1_c0', 'AJG'),\n",
       " ('c1_c0', 'AKAM'),\n",
       " ('c1_c0', 'ALB'),\n",
       " ('c1_c0', 'ALK'),\n",
       " ('c1_c0', 'ALL'),\n",
       " ('c1_c0', 'ALLE'),\n",
       " ('c1_c0', 'ALXN'),\n",
       " ('c1_c0', 'AMAT'),\n",
       " ('c1_c0', 'AMD'),\n",
       " ('c1_c0', 'AME'),\n",
       " ('c1_c0', 'AMG'),\n",
       " ('c1_c0', 'AMGN'),\n",
       " ('c1_c0', 'AMP'),\n",
       " ('c1_c0', 'AMT'),\n",
       " ('c1_c0', 'ANSS'),\n",
       " ('c1_c0', 'ANTM'),\n",
       " ('c1_c0', 'AON'),\n",
       " ('c1_c0', 'AOS'),\n",
       " ('c1_c0', 'APA'),\n",
       " ('c1_c0', 'APC'),\n",
       " ('c1_c0', 'APD'),\n",
       " ('c1_c0', 'APH'),\n",
       " ('c1_c0', 'ARE'),\n",
       " ('c1_c0', 'ARNC'),\n",
       " ('c1_c0', 'ATVI'),\n",
       " ('c1_c0', 'AVB'),\n",
       " ('c1_c0', 'AVGO'),\n",
       " ('c1_c0', 'AVY'),\n",
       " ('c1_c0', 'AYI'),\n",
       " ('c1_c0', 'AZO'),\n",
       " ('c1_c0', 'BA'),\n",
       " ('c1_c0', 'BAX'),\n",
       " ('c1_c0', 'BBT'),\n",
       " ('c1_c0', 'BBY'),\n",
       " ('c1_c0', 'BCR'),\n",
       " ('c1_c0', 'BDX'),\n",
       " ('c1_c0', 'BEN'),\n",
       " ('c1_c0', 'BHF'),\n",
       " ('c1_c0', 'BHGE'),\n",
       " ('c1_c0', 'BIIB'),\n",
       " ('c1_c0', 'BK'),\n",
       " ('c1_c0', 'BLL'),\n",
       " ('c1_c0', 'BMY'),\n",
       " ('c1_c0', 'BWA'),\n",
       " ('c1_c0', 'BXP'),\n",
       " ('c1_c0', 'CA'),\n",
       " ('c1_c0', 'CAH'),\n",
       " ('c1_c0', 'CB'),\n",
       " ('c1_c0', 'CBOE'),\n",
       " ('c1_c0', 'CBS'),\n",
       " ('c1_c0', 'CCI'),\n",
       " ('c1_c0', 'CDNS'),\n",
       " ('c1_c0', 'CELG'),\n",
       " ('c1_c0', 'CERN'),\n",
       " ('c1_c0', 'CF'),\n",
       " ('c1_c0', 'CHD'),\n",
       " ('c1_c0', 'CHK'),\n",
       " ('c1_c0', 'CHRW'),\n",
       " ('c1_c0', 'CHTR'),\n",
       " ('c1_c0', 'CI'),\n",
       " ('c1_c0', 'CL'),\n",
       " ('c1_c0', 'CLX'),\n",
       " ('c1_c0', 'CMA'),\n",
       " ('c1_c0', 'CMCSA'),\n",
       " ('c1_c0', 'CMG'),\n",
       " ('c1_c0', 'CMS'),\n",
       " ('c1_c0', 'CNC'),\n",
       " ('c1_c0', 'CNP'),\n",
       " ('c1_c0', 'COF'),\n",
       " ('c1_c0', 'COG'),\n",
       " ('c1_c0', 'COH'),\n",
       " ('c1_c0', 'COL'),\n",
       " ('c1_c0', 'COO'),\n",
       " ('c1_c0', 'COP'),\n",
       " ('c1_c0', 'COST'),\n",
       " ('c1_c0', 'COTY'),\n",
       " ('c1_c0', 'CPB'),\n",
       " ('c1_c0', 'CRM'),\n",
       " ('c1_c0', 'CSCO'),\n",
       " ('c1_c0', 'CSRA'),\n",
       " ('c1_c0', 'CSX'),\n",
       " ('c1_c0', 'CTAS'),\n",
       " ('c1_c0', 'CTL'),\n",
       " ('c1_c0', 'CTSH'),\n",
       " ('c1_c0', 'CTXS'),\n",
       " ('c1_c0', 'CVS'),\n",
       " ('c1_c0', 'CVX'),\n",
       " ('c1_c0', 'D'),\n",
       " ('c1_c0', 'DAL'),\n",
       " ('c1_c0', 'DE'),\n",
       " ('c1_c0', 'DFS'),\n",
       " ('c1_c0', 'DG'),\n",
       " ('c1_c0', 'DGX'),\n",
       " ('c1_c0', 'DHI'),\n",
       " ('c1_c0', 'DHR'),\n",
       " ('c1_c0', 'DISCA'),\n",
       " ('c1_c0', 'DISCK'),\n",
       " ('c1_c0', 'DLPH'),\n",
       " ('c1_c0', 'DLR'),\n",
       " ('c1_c0', 'DLTR'),\n",
       " ('c1_c0', 'DOV'),\n",
       " ('c1_c0', 'DPS'),\n",
       " ('c1_c0', 'DRE'),\n",
       " ('c1_c0', 'DRI'),\n",
       " ('c1_c0', 'DUK'),\n",
       " ('c1_c0', 'DVN'),\n",
       " ('c1_c0', 'DWDP'),\n",
       " ('c1_c0', 'DXC'),\n",
       " ('c1_c0', 'EA'),\n",
       " ('c1_c0', 'ECL'),\n",
       " ('c1_c0', 'EFX'),\n",
       " ('c1_c0', 'EL'),\n",
       " ('c1_c0', 'EMN'),\n",
       " ('c1_c0', 'EMR'),\n",
       " ('c1_c0', 'EOG'),\n",
       " ('c1_c0', 'EQIX'),\n",
       " ('c1_c0', 'EQR'),\n",
       " ('c1_c0', 'EQT'),\n",
       " ('c1_c0', 'ES'),\n",
       " ('c1_c0', 'ESS'),\n",
       " ('c1_c0', 'ETFC'),\n",
       " ('c1_c0', 'ETN'),\n",
       " ('c1_c0', 'ETR'),\n",
       " ('c1_c0', 'EVHC'),\n",
       " ('c1_c0', 'EW'),\n",
       " ('c1_c0', 'EXC'),\n",
       " ('c1_c0', 'EXPD'),\n",
       " ('c1_c0', 'EXPE'),\n",
       " ('c1_c0', 'EXR'),\n",
       " ('c1_c0', 'F'),\n",
       " ('c1_c0', 'FAST'),\n",
       " ('c1_c0', 'FB'),\n",
       " ('c1_c0', 'FBHS'),\n",
       " ('c1_c0', 'FCX'),\n",
       " ('c1_c0', 'FDX'),\n",
       " ('c1_c0', 'FE'),\n",
       " ('c1_c0', 'FFIV'),\n",
       " ('c1_c0', 'FIS'),\n",
       " ('c1_c0', 'FISV'),\n",
       " ('c1_c0', 'FITB'),\n",
       " ('c1_c0', 'FL'),\n",
       " ('c1_c0', 'FLIR'),\n",
       " ('c1_c0', 'FLR'),\n",
       " ('c1_c0', 'FLS'),\n",
       " ('c1_c0', 'FMC'),\n",
       " ('c1_c0', 'FOX'),\n",
       " ('c1_c0', 'FRT'),\n",
       " ('c1_c0', 'FTI'),\n",
       " ('c1_c0', 'FTV'),\n",
       " ('c1_c0', 'GD'),\n",
       " ('c1_c0', 'GE'),\n",
       " ('c1_c0', 'GILD'),\n",
       " ('c1_c0', 'GIS'),\n",
       " ('c1_c0', 'GLW'),\n",
       " ('c1_c0', 'GM'),\n",
       " ('c1_c0', 'GOOG'),\n",
       " ('c1_c0', 'GOOGL'),\n",
       " ('c1_c0', 'GPC'),\n",
       " ('c1_c0', 'GPS'),\n",
       " ('c1_c0', 'GRMN'),\n",
       " ('c1_c0', 'GS'),\n",
       " ('c1_c0', 'GT'),\n",
       " ('c1_c0', 'GWW'),\n",
       " ('c1_c0', 'HAL'),\n",
       " ('c1_c0', 'HAS'),\n",
       " ('c1_c0', 'HBAN'),\n",
       " ('c1_c0', 'HBI'),\n",
       " ('c1_c0', 'HCA'),\n",
       " ('c1_c0', 'HCN'),\n",
       " ('c1_c0', 'HCP'),\n",
       " ('c1_c0', 'HES'),\n",
       " ('c1_c0', 'HIG'),\n",
       " ('c1_c0', 'HOLX'),\n",
       " ('c1_c0', 'HON'),\n",
       " ('c1_c0', 'HP'),\n",
       " ('c1_c0', 'HPE'),\n",
       " ('c1_c0', 'HRB'),\n",
       " ('c1_c0', 'HRL'),\n",
       " ('c1_c0', 'HRS'),\n",
       " ('c1_c0', 'HSIC'),\n",
       " ('c1_c0', 'HST'),\n",
       " ('c1_c0', 'HSY'),\n",
       " ('c1_c0', 'HUM'),\n",
       " ('c1_c0', 'IBM'),\n",
       " ('c1_c0', 'ICE'),\n",
       " ('c1_c0', 'IDXX'),\n",
       " ('c1_c0', 'IFF'),\n",
       " ('c1_c0', 'ILMN'),\n",
       " ('c1_c0', 'INCY'),\n",
       " ('c1_c0', 'INTC'),\n",
       " ('c1_c0', 'INTU'),\n",
       " ('c1_c0', 'IP'),\n",
       " ('c1_c0', 'IPG'),\n",
       " ('c1_c0', 'IR'),\n",
       " ('c1_c0', 'IRM'),\n",
       " ('c1_c0', 'ISRG'),\n",
       " ('c1_c0', 'IT'),\n",
       " ('c1_c0', 'IVZ'),\n",
       " ('c1_c0', 'JBHT'),\n",
       " ('c1_c0', 'JCI'),\n",
       " ('c1_c0', 'JEC'),\n",
       " ('c1_c0', 'JNPR'),\n",
       " ('c1_c0', 'JPM'),\n",
       " ('c1_c0', 'JWN'),\n",
       " ('c1_c0', 'KHC'),\n",
       " ('c1_c0', 'KIM'),\n",
       " ('c1_c0', 'KMB'),\n",
       " ('c1_c0', 'KMI'),\n",
       " ('c1_c0', 'KMX'),\n",
       " ('c1_c0', 'KO'),\n",
       " ('c1_c0', 'KORS'),\n",
       " ('c1_c0', 'KR'),\n",
       " ('c1_c0', 'KSS'),\n",
       " ('c1_c0', 'KSU'),\n",
       " ('c1_c0', 'L'),\n",
       " ('c1_c0', 'LEN'),\n",
       " ('c1_c0', 'LH'),\n",
       " ('c1_c0', 'LKQ'),\n",
       " ('c1_c0', 'LLY'),\n",
       " ('c1_c0', 'LMT'),\n",
       " ('c1_c0', 'LNT'),\n",
       " ('c1_c0', 'LOW'),\n",
       " ('c1_c0', 'LUK'),\n",
       " ('c1_c0', 'LUV'),\n",
       " ('c1_c0', 'LVLT'),\n",
       " ('c1_c0', 'LYB'),\n",
       " ('c1_c0', 'M'),\n",
       " ('c1_c0', 'MA'),\n",
       " ('c1_c0', 'MAA'),\n",
       " ('c1_c0', 'MAC'),\n",
       " ('c1_c0', 'MAR'),\n",
       " ('c1_c0', 'MAS'),\n",
       " ('c1_c0', 'MAT'),\n",
       " ('c1_c0', 'MCD'),\n",
       " ('c1_c0', 'MCK'),\n",
       " ('c1_c0', 'MCO'),\n",
       " ('c1_c0', 'MDLZ'),\n",
       " ('c1_c0', 'MDT'),\n",
       " ('c1_c0', 'MET'),\n",
       " ('c1_c0', 'MGM'),\n",
       " ('c1_c0', 'MHK'),\n",
       " ('c1_c0', 'MKC'),\n",
       " ('c1_c0', 'MMC'),\n",
       " ('c1_c0', 'MNST'),\n",
       " ('c1_c0', 'MO'),\n",
       " ('c1_c0', 'MOS'),\n",
       " ('c1_c0', 'MPC'),\n",
       " ('c1_c0', 'MRK'),\n",
       " ('c1_c0', 'MRO'),\n",
       " ('c1_c0', 'MS'),\n",
       " ('c1_c0', 'MSFT'),\n",
       " ('c1_c0', 'MSI'),\n",
       " ('c1_c0', 'MTB'),\n",
       " ('c1_c0', 'MTD'),\n",
       " ('c1_c0', 'MU'),\n",
       " ('c1_c0', 'MYL'),\n",
       " ('c1_c0', 'NAVI'),\n",
       " ('c1_c0', 'NBL'),\n",
       " ('c1_c0', 'NEE'),\n",
       " ('c1_c0', 'NFLX'),\n",
       " ('c1_c0', 'NI'),\n",
       " ('c1_c0', 'NKE'),\n",
       " ('c1_c0', 'NLSN'),\n",
       " ('c1_c0', 'NOC'),\n",
       " ('c1_c0', 'NOV'),\n",
       " ('c1_c0', 'NRG'),\n",
       " ('c1_c0', 'NSC'),\n",
       " ('c1_c0', 'NTAP'),\n",
       " ('c1_c0', 'NTRS'),\n",
       " ('c1_c0', 'NUE'),\n",
       " ('c1_c0', 'NVDA'),\n",
       " ('c1_c0', 'NWL'),\n",
       " ('c1_c0', 'NWS'),\n",
       " ('c1_c0', 'NWSA'),\n",
       " ('c1_c0', 'OKE'),\n",
       " ('c1_c0', 'OMC'),\n",
       " ('c1_c0', 'ORLY'),\n",
       " ('c1_c0', 'OXY'),\n",
       " ('c1_c0', 'PAYX'),\n",
       " ('c1_c0', 'PBCT'),\n",
       " ('c1_c0', 'PCAR'),\n",
       " ('c1_c0', 'PCG'),\n",
       " ('c1_c0', 'PCLN'),\n",
       " ('c1_c0', 'PDCO'),\n",
       " ('c1_c0', 'PEG'),\n",
       " ('c1_c0', 'PEP'),\n",
       " ('c1_c0', 'PFE'),\n",
       " ('c1_c0', 'PFG'),\n",
       " ('c1_c0', 'PG'),\n",
       " ('c1_c0', 'PH'),\n",
       " ('c1_c0', 'PHM'),\n",
       " ('c1_c0', 'PKG'),\n",
       " ('c1_c0', 'PKI'),\n",
       " ('c1_c0', 'PM'),\n",
       " ('c1_c0', 'PNC'),\n",
       " ('c1_c0', 'PNR'),\n",
       " ('c1_c0', 'PPG'),\n",
       " ('c1_c0', 'PPL'),\n",
       " ('c1_c0', 'PRGO'),\n",
       " ('c1_c0', 'PRU'),\n",
       " ('c1_c0', 'PSA'),\n",
       " ('c1_c0', 'PSX'),\n",
       " ('c1_c0', 'PWR'),\n",
       " ('c1_c0', 'PX'),\n",
       " ('c1_c0', 'PXD'),\n",
       " ('c1_c0', 'Q'),\n",
       " ('c1_c0', 'QCOM'),\n",
       " ('c1_c0', 'QRVO'),\n",
       " ('c1_c0', 'RCL'),\n",
       " ('c1_c0', 'REG'),\n",
       " ('c1_c0', 'REGN'),\n",
       " ('c1_c0', 'RF'),\n",
       " ('c1_c0', 'RHT'),\n",
       " ('c1_c0', 'RJF'),\n",
       " ('c1_c0', 'RL'),\n",
       " ('c1_c0', 'RMD'),\n",
       " ('c1_c0', 'ROK'),\n",
       " ('c1_c0', 'ROP'),\n",
       " ('c1_c0', 'ROST'),\n",
       " ('c1_c0', 'RRC'),\n",
       " ('c1_c0', 'RSG'),\n",
       " ('c1_c0', 'RTN'),\n",
       " ('c1_c0', 'SBUX'),\n",
       " ('c1_c0', 'SCG'),\n",
       " ('c1_c0', 'SCHW'),\n",
       " ('c1_c0', 'SEE'),\n",
       " ('c1_c0', 'SHW'),\n",
       " ('c1_c0', 'SIG'),\n",
       " ('c1_c0', 'SJM'),\n",
       " ('c1_c0', 'SLG'),\n",
       " ('c1_c0', 'SNI'),\n",
       " ('c1_c0', 'SNPS'),\n",
       " ('c1_c0', 'SO'),\n",
       " ('c1_c0', 'SRCL'),\n",
       " ('c1_c0', 'SRE'),\n",
       " ('c1_c0', 'STI'),\n",
       " ('c1_c0', 'STT'),\n",
       " ('c1_c0', 'STX'),\n",
       " ('c1_c0', 'SWK'),\n",
       " ('c1_c0', 'SYF'),\n",
       " ('c1_c0', 'SYMC'),\n",
       " ('c1_c0', 'SYY'),\n",
       " ('c1_c0', 'T'),\n",
       " ('c1_c0', 'TEL'),\n",
       " ('c1_c0', 'TGT'),\n",
       " ('c1_c0', 'TIF'),\n",
       " ('c1_c0', 'TJX'),\n",
       " ('c1_c0', 'TMK'),\n",
       " ('c1_c0', 'TMO'),\n",
       " ('c1_c0', 'TRIP'),\n",
       " ('c1_c0', 'TROW'),\n",
       " ('c1_c0', 'TRV'),\n",
       " ('c1_c0', 'TSCO'),\n",
       " ('c1_c0', 'TWX'),\n",
       " ('c1_c0', 'TXN'),\n",
       " ('c1_c0', 'TXT'),\n",
       " ('c1_c0', 'UAA'),\n",
       " ('c1_c0', 'UAL'),\n",
       " ('c1_c0', 'UDR'),\n",
       " ('c1_c0', 'UHS'),\n",
       " ('c1_c0', 'ULTA'),\n",
       " ('c1_c0', 'UNH'),\n",
       " ('c1_c0', 'UNM'),\n",
       " ('c1_c0', 'UNP'),\n",
       " ('c1_c0', 'UPS'),\n",
       " ('c1_c0', 'URI'),\n",
       " ('c1_c0', 'USB'),\n",
       " ('c1_c0', 'UTX'),\n",
       " ('c1_c0', 'V'),\n",
       " ('c1_c0', 'VAR'),\n",
       " ('c1_c0', 'VFC'),\n",
       " ('c1_c0', 'VIAB'),\n",
       " ('c1_c0', 'VLO'),\n",
       " ('c1_c0', 'VMC'),\n",
       " ('c1_c0', 'VNO'),\n",
       " ('c1_c0', 'VRSK'),\n",
       " ('c1_c0', 'VRSN'),\n",
       " ('c1_c0', 'VRTX'),\n",
       " ('c1_c0', 'VTR'),\n",
       " ('c1_c0', 'WAT'),\n",
       " ('c1_c0', 'WBA'),\n",
       " ('c1_c0', 'WEC'),\n",
       " ('c1_c0', 'WFC'),\n",
       " ('c1_c0', 'WHR'),\n",
       " ('c1_c0', 'WLTW'),\n",
       " ('c1_c0', 'WM'),\n",
       " ('c1_c0', 'WMB'),\n",
       " ('c1_c0', 'WMT'),\n",
       " ('c1_c0', 'WRK'),\n",
       " ('c1_c0', 'WU'),\n",
       " ('c1_c0', 'WY'),\n",
       " ('c1_c0', 'WYN'),\n",
       " ('c1_c0', 'WYNN'),\n",
       " ('c1_c0', 'XEC'),\n",
       " ('c1_c0', 'XEL'),\n",
       " ('c1_c0', 'XL'),\n",
       " ('c1_c0', 'XLNX'),\n",
       " ('c1_c0', 'XOM'),\n",
       " ('c1_c0', 'XRAY'),\n",
       " ('c1_c0', 'XRX'),\n",
       " ('c1_c0', 'XYL'),\n",
       " ('c1_c0', 'ZBH'),\n",
       " ('c1_c0', 'ZION'),\n",
       " ('c1_c0', 'ZTS'),\n",
       " ('c_2_h', 'A'),\n",
       " ('c_2_h', 'AAL'),\n",
       " ('c_2_h', 'AAP'),\n",
       " ('c_2_h', 'AAPL'),\n",
       " ('c_2_h', 'ABBV'),\n",
       " ('c_2_h', 'ABC'),\n",
       " ('c_2_h', 'ACN'),\n",
       " ('c_2_h', 'ADBE'),\n",
       " ('c_2_h', 'ADI'),\n",
       " ('c_2_h', 'ADM'),\n",
       " ('c_2_h', 'ADSK'),\n",
       " ('c_2_h', 'AEE'),\n",
       " ('c_2_h', 'AEP'),\n",
       " ('c_2_h', 'AES'),\n",
       " ('c_2_h', 'AET'),\n",
       " ('c_2_h', 'AFL'),\n",
       " ('c_2_h', 'AGN'),\n",
       " ('c_2_h', 'AIG'),\n",
       " ('c_2_h', 'AIV'),\n",
       " ('c_2_h', 'AIZ'),\n",
       " ('c_2_h', 'AJG'),\n",
       " ('c_2_h', 'AKAM'),\n",
       " ('c_2_h', 'ALB'),\n",
       " ('c_2_h', 'ALK'),\n",
       " ('c_2_h', 'ALL'),\n",
       " ('c_2_h', 'ALLE'),\n",
       " ('c_2_h', 'ALXN'),\n",
       " ('c_2_h', 'AMAT'),\n",
       " ('c_2_h', 'AMD'),\n",
       " ('c_2_h', 'AME'),\n",
       " ('c_2_h', 'AMG'),\n",
       " ('c_2_h', 'AMGN'),\n",
       " ('c_2_h', 'AMP'),\n",
       " ('c_2_h', 'AMT'),\n",
       " ('c_2_h', 'ANSS'),\n",
       " ('c_2_h', 'ANTM'),\n",
       " ('c_2_h', 'AON'),\n",
       " ('c_2_h', 'AOS'),\n",
       " ('c_2_h', 'APA'),\n",
       " ('c_2_h', 'APC'),\n",
       " ('c_2_h', 'APD'),\n",
       " ('c_2_h', 'APH'),\n",
       " ('c_2_h', 'ARE'),\n",
       " ('c_2_h', 'ARNC'),\n",
       " ('c_2_h', 'ATVI'),\n",
       " ('c_2_h', 'AVB'),\n",
       " ('c_2_h', 'AVGO'),\n",
       " ('c_2_h', 'AVY'),\n",
       " ('c_2_h', 'AYI'),\n",
       " ('c_2_h', 'AZO'),\n",
       " ('c_2_h', 'BA'),\n",
       " ('c_2_h', 'BAX'),\n",
       " ('c_2_h', 'BBT'),\n",
       " ('c_2_h', 'BBY'),\n",
       " ('c_2_h', 'BCR'),\n",
       " ('c_2_h', 'BDX'),\n",
       " ('c_2_h', 'BEN'),\n",
       " ('c_2_h', 'BHF'),\n",
       " ('c_2_h', 'BHGE'),\n",
       " ('c_2_h', 'BIIB'),\n",
       " ('c_2_h', 'BK'),\n",
       " ('c_2_h', 'BLL'),\n",
       " ('c_2_h', 'BMY'),\n",
       " ('c_2_h', 'BWA'),\n",
       " ('c_2_h', 'BXP'),\n",
       " ('c_2_h', 'CA'),\n",
       " ('c_2_h', 'CAH'),\n",
       " ('c_2_h', 'CB'),\n",
       " ('c_2_h', 'CBOE'),\n",
       " ('c_2_h', 'CBS'),\n",
       " ('c_2_h', 'CCI'),\n",
       " ('c_2_h', 'CDNS'),\n",
       " ('c_2_h', 'CELG'),\n",
       " ('c_2_h', 'CERN'),\n",
       " ('c_2_h', 'CF'),\n",
       " ('c_2_h', 'CHD'),\n",
       " ('c_2_h', 'CHK'),\n",
       " ('c_2_h', 'CHRW'),\n",
       " ('c_2_h', 'CHTR'),\n",
       " ('c_2_h', 'CI'),\n",
       " ('c_2_h', 'CL'),\n",
       " ('c_2_h', 'CLX'),\n",
       " ('c_2_h', 'CMA'),\n",
       " ('c_2_h', 'CMCSA'),\n",
       " ('c_2_h', 'CMG'),\n",
       " ('c_2_h', 'CMS'),\n",
       " ('c_2_h', 'CNC'),\n",
       " ('c_2_h', 'CNP'),\n",
       " ('c_2_h', 'COF'),\n",
       " ('c_2_h', 'COG'),\n",
       " ('c_2_h', 'COH'),\n",
       " ('c_2_h', 'COL'),\n",
       " ('c_2_h', 'COO'),\n",
       " ('c_2_h', 'COP'),\n",
       " ('c_2_h', 'COST'),\n",
       " ('c_2_h', 'COTY'),\n",
       " ('c_2_h', 'CPB'),\n",
       " ('c_2_h', 'CRM'),\n",
       " ('c_2_h', 'CSCO'),\n",
       " ('c_2_h', 'CSRA'),\n",
       " ('c_2_h', 'CSX'),\n",
       " ('c_2_h', 'CTAS'),\n",
       " ('c_2_h', 'CTL'),\n",
       " ('c_2_h', 'CTSH'),\n",
       " ('c_2_h', 'CTXS'),\n",
       " ('c_2_h', 'CVS'),\n",
       " ('c_2_h', 'CVX'),\n",
       " ('c_2_h', 'D'),\n",
       " ('c_2_h', 'DAL'),\n",
       " ('c_2_h', 'DE'),\n",
       " ('c_2_h', 'DFS'),\n",
       " ('c_2_h', 'DG'),\n",
       " ('c_2_h', 'DGX'),\n",
       " ('c_2_h', 'DHI'),\n",
       " ('c_2_h', 'DHR'),\n",
       " ('c_2_h', 'DISCA'),\n",
       " ('c_2_h', 'DISCK'),\n",
       " ('c_2_h', 'DLPH'),\n",
       " ('c_2_h', 'DLR'),\n",
       " ('c_2_h', 'DLTR'),\n",
       " ('c_2_h', 'DOV'),\n",
       " ('c_2_h', 'DPS'),\n",
       " ('c_2_h', 'DRE'),\n",
       " ('c_2_h', 'DRI'),\n",
       " ('c_2_h', 'DUK'),\n",
       " ('c_2_h', 'DVN'),\n",
       " ('c_2_h', 'DWDP'),\n",
       " ('c_2_h', 'DXC'),\n",
       " ('c_2_h', 'EA'),\n",
       " ('c_2_h', 'ECL'),\n",
       " ('c_2_h', 'EFX'),\n",
       " ('c_2_h', 'EL'),\n",
       " ('c_2_h', 'EMN'),\n",
       " ('c_2_h', 'EMR'),\n",
       " ('c_2_h', 'EOG'),\n",
       " ('c_2_h', 'EQIX'),\n",
       " ('c_2_h', 'EQR'),\n",
       " ('c_2_h', 'EQT'),\n",
       " ('c_2_h', 'ES'),\n",
       " ('c_2_h', 'ESS'),\n",
       " ('c_2_h', 'ETFC'),\n",
       " ('c_2_h', 'ETN'),\n",
       " ('c_2_h', 'ETR'),\n",
       " ('c_2_h', 'EVHC'),\n",
       " ('c_2_h', 'EW'),\n",
       " ('c_2_h', 'EXC'),\n",
       " ('c_2_h', 'EXPD'),\n",
       " ('c_2_h', 'EXPE'),\n",
       " ('c_2_h', 'EXR'),\n",
       " ('c_2_h', 'F'),\n",
       " ('c_2_h', 'FAST'),\n",
       " ('c_2_h', 'FB'),\n",
       " ('c_2_h', 'FBHS'),\n",
       " ('c_2_h', 'FCX'),\n",
       " ('c_2_h', 'FDX'),\n",
       " ('c_2_h', 'FE'),\n",
       " ('c_2_h', 'FFIV'),\n",
       " ('c_2_h', 'FIS'),\n",
       " ('c_2_h', 'FISV'),\n",
       " ('c_2_h', 'FITB'),\n",
       " ('c_2_h', 'FL'),\n",
       " ('c_2_h', 'FLIR'),\n",
       " ('c_2_h', 'FLR'),\n",
       " ('c_2_h', 'FLS'),\n",
       " ('c_2_h', 'FMC'),\n",
       " ('c_2_h', 'FOX'),\n",
       " ('c_2_h', 'FRT'),\n",
       " ('c_2_h', 'FTI'),\n",
       " ('c_2_h', 'FTV'),\n",
       " ('c_2_h', 'GD'),\n",
       " ('c_2_h', 'GE'),\n",
       " ('c_2_h', 'GILD'),\n",
       " ('c_2_h', 'GIS'),\n",
       " ('c_2_h', 'GLW'),\n",
       " ('c_2_h', 'GM'),\n",
       " ('c_2_h', 'GOOG'),\n",
       " ('c_2_h', 'GOOGL'),\n",
       " ('c_2_h', 'GPC'),\n",
       " ('c_2_h', 'GPS'),\n",
       " ('c_2_h', 'GRMN'),\n",
       " ('c_2_h', 'GS'),\n",
       " ('c_2_h', 'GT'),\n",
       " ('c_2_h', 'GWW'),\n",
       " ('c_2_h', 'HAL'),\n",
       " ('c_2_h', 'HAS'),\n",
       " ('c_2_h', 'HBAN'),\n",
       " ('c_2_h', 'HBI'),\n",
       " ('c_2_h', 'HCA'),\n",
       " ('c_2_h', 'HCN'),\n",
       " ('c_2_h', 'HCP'),\n",
       " ('c_2_h', 'HES'),\n",
       " ('c_2_h', 'HIG'),\n",
       " ('c_2_h', 'HOLX'),\n",
       " ('c_2_h', 'HON'),\n",
       " ('c_2_h', 'HP'),\n",
       " ('c_2_h', 'HPE'),\n",
       " ('c_2_h', 'HRB'),\n",
       " ('c_2_h', 'HRL'),\n",
       " ('c_2_h', 'HRS'),\n",
       " ('c_2_h', 'HSIC'),\n",
       " ('c_2_h', 'HST'),\n",
       " ('c_2_h', 'HSY'),\n",
       " ('c_2_h', 'HUM'),\n",
       " ('c_2_h', 'IBM'),\n",
       " ('c_2_h', 'ICE'),\n",
       " ('c_2_h', 'IDXX'),\n",
       " ('c_2_h', 'IFF'),\n",
       " ('c_2_h', 'ILMN'),\n",
       " ('c_2_h', 'INCY'),\n",
       " ('c_2_h', 'INTC'),\n",
       " ('c_2_h', 'INTU'),\n",
       " ('c_2_h', 'IP'),\n",
       " ('c_2_h', 'IPG'),\n",
       " ('c_2_h', 'IR'),\n",
       " ('c_2_h', 'IRM'),\n",
       " ('c_2_h', 'ISRG'),\n",
       " ('c_2_h', 'IT'),\n",
       " ('c_2_h', 'IVZ'),\n",
       " ('c_2_h', 'JBHT'),\n",
       " ('c_2_h', 'JCI'),\n",
       " ('c_2_h', 'JEC'),\n",
       " ('c_2_h', 'JNPR'),\n",
       " ('c_2_h', 'JPM'),\n",
       " ('c_2_h', 'JWN'),\n",
       " ('c_2_h', 'KHC'),\n",
       " ('c_2_h', 'KIM'),\n",
       " ('c_2_h', 'KMB'),\n",
       " ('c_2_h', 'KMI'),\n",
       " ('c_2_h', 'KMX'),\n",
       " ('c_2_h', 'KO'),\n",
       " ('c_2_h', 'KORS'),\n",
       " ('c_2_h', 'KR'),\n",
       " ('c_2_h', 'KSS'),\n",
       " ('c_2_h', 'KSU'),\n",
       " ('c_2_h', 'L'),\n",
       " ('c_2_h', 'LEN'),\n",
       " ('c_2_h', 'LH'),\n",
       " ('c_2_h', 'LKQ'),\n",
       " ('c_2_h', 'LLY'),\n",
       " ('c_2_h', 'LMT'),\n",
       " ('c_2_h', 'LNT'),\n",
       " ('c_2_h', 'LOW'),\n",
       " ('c_2_h', 'LUK'),\n",
       " ('c_2_h', 'LUV'),\n",
       " ('c_2_h', 'LVLT'),\n",
       " ('c_2_h', 'LYB'),\n",
       " ('c_2_h', 'M'),\n",
       " ('c_2_h', 'MA'),\n",
       " ('c_2_h', 'MAA'),\n",
       " ('c_2_h', 'MAC'),\n",
       " ('c_2_h', 'MAR'),\n",
       " ('c_2_h', 'MAS'),\n",
       " ('c_2_h', 'MAT'),\n",
       " ('c_2_h', 'MCD'),\n",
       " ('c_2_h', 'MCK'),\n",
       " ('c_2_h', 'MCO'),\n",
       " ('c_2_h', 'MDLZ'),\n",
       " ('c_2_h', 'MDT'),\n",
       " ('c_2_h', 'MET'),\n",
       " ('c_2_h', 'MGM'),\n",
       " ('c_2_h', 'MHK'),\n",
       " ('c_2_h', 'MKC'),\n",
       " ('c_2_h', 'MMC'),\n",
       " ('c_2_h', 'MNST'),\n",
       " ('c_2_h', 'MO'),\n",
       " ('c_2_h', 'MOS'),\n",
       " ('c_2_h', 'MPC'),\n",
       " ('c_2_h', 'MRK'),\n",
       " ('c_2_h', 'MRO'),\n",
       " ('c_2_h', 'MS'),\n",
       " ('c_2_h', 'MSFT'),\n",
       " ('c_2_h', 'MSI'),\n",
       " ('c_2_h', 'MTB'),\n",
       " ('c_2_h', 'MTD'),\n",
       " ('c_2_h', 'MU'),\n",
       " ('c_2_h', 'MYL'),\n",
       " ('c_2_h', 'NAVI'),\n",
       " ('c_2_h', 'NBL'),\n",
       " ('c_2_h', 'NEE'),\n",
       " ('c_2_h', 'NFLX'),\n",
       " ('c_2_h', 'NI'),\n",
       " ('c_2_h', 'NKE'),\n",
       " ('c_2_h', 'NLSN'),\n",
       " ('c_2_h', 'NOC'),\n",
       " ('c_2_h', 'NOV'),\n",
       " ('c_2_h', 'NRG'),\n",
       " ('c_2_h', 'NSC'),\n",
       " ('c_2_h', 'NTAP'),\n",
       " ('c_2_h', 'NTRS'),\n",
       " ('c_2_h', 'NUE'),\n",
       " ('c_2_h', 'NVDA'),\n",
       " ('c_2_h', 'NWL'),\n",
       " ('c_2_h', 'NWS'),\n",
       " ('c_2_h', 'NWSA'),\n",
       " ('c_2_h', 'OKE'),\n",
       " ('c_2_h', 'OMC'),\n",
       " ('c_2_h', 'ORLY'),\n",
       " ('c_2_h', 'OXY'),\n",
       " ('c_2_h', 'PAYX'),\n",
       " ('c_2_h', 'PBCT'),\n",
       " ('c_2_h', 'PCAR'),\n",
       " ('c_2_h', 'PCG'),\n",
       " ('c_2_h', 'PCLN'),\n",
       " ('c_2_h', 'PDCO'),\n",
       " ('c_2_h', 'PEG'),\n",
       " ('c_2_h', 'PEP'),\n",
       " ('c_2_h', 'PFE'),\n",
       " ('c_2_h', 'PFG'),\n",
       " ('c_2_h', 'PG'),\n",
       " ('c_2_h', 'PH'),\n",
       " ('c_2_h', 'PHM'),\n",
       " ('c_2_h', 'PKG'),\n",
       " ('c_2_h', 'PKI'),\n",
       " ('c_2_h', 'PM'),\n",
       " ('c_2_h', 'PNC'),\n",
       " ('c_2_h', 'PNR'),\n",
       " ('c_2_h', 'PPG'),\n",
       " ('c_2_h', 'PPL'),\n",
       " ('c_2_h', 'PRGO'),\n",
       " ('c_2_h', 'PRU'),\n",
       " ('c_2_h', 'PSA'),\n",
       " ('c_2_h', 'PSX'),\n",
       " ('c_2_h', 'PWR'),\n",
       " ('c_2_h', 'PX'),\n",
       " ('c_2_h', 'PXD'),\n",
       " ('c_2_h', 'Q'),\n",
       " ('c_2_h', 'QCOM'),\n",
       " ('c_2_h', 'QRVO'),\n",
       " ('c_2_h', 'RCL'),\n",
       " ('c_2_h', 'REG'),\n",
       " ('c_2_h', 'REGN'),\n",
       " ('c_2_h', 'RF'),\n",
       " ('c_2_h', 'RHT'),\n",
       " ('c_2_h', 'RJF'),\n",
       " ('c_2_h', 'RL'),\n",
       " ('c_2_h', 'RMD'),\n",
       " ('c_2_h', 'ROK'),\n",
       " ('c_2_h', 'ROP'),\n",
       " ('c_2_h', 'ROST'),\n",
       " ('c_2_h', 'RRC'),\n",
       " ('c_2_h', 'RSG'),\n",
       " ('c_2_h', 'RTN'),\n",
       " ('c_2_h', 'SBUX'),\n",
       " ('c_2_h', 'SCG'),\n",
       " ('c_2_h', 'SCHW'),\n",
       " ('c_2_h', 'SEE'),\n",
       " ('c_2_h', 'SHW'),\n",
       " ('c_2_h', 'SIG'),\n",
       " ('c_2_h', 'SJM'),\n",
       " ('c_2_h', 'SLG'),\n",
       " ('c_2_h', 'SNI'),\n",
       " ('c_2_h', 'SNPS'),\n",
       " ('c_2_h', 'SO'),\n",
       " ('c_2_h', 'SRCL'),\n",
       " ('c_2_h', 'SRE'),\n",
       " ('c_2_h', 'STI'),\n",
       " ('c_2_h', 'STT'),\n",
       " ('c_2_h', 'STX'),\n",
       " ('c_2_h', 'SWK'),\n",
       " ('c_2_h', 'SYF'),\n",
       " ('c_2_h', 'SYMC'),\n",
       " ('c_2_h', 'SYY'),\n",
       " ('c_2_h', 'T'),\n",
       " ('c_2_h', 'TEL'),\n",
       " ('c_2_h', 'TGT'),\n",
       " ('c_2_h', 'TIF'),\n",
       " ('c_2_h', 'TJX'),\n",
       " ('c_2_h', 'TMK'),\n",
       " ('c_2_h', 'TMO'),\n",
       " ('c_2_h', 'TRIP'),\n",
       " ('c_2_h', 'TROW'),\n",
       " ('c_2_h', 'TRV'),\n",
       " ('c_2_h', 'TSCO'),\n",
       " ('c_2_h', 'TWX'),\n",
       " ('c_2_h', 'TXN'),\n",
       " ('c_2_h', 'TXT'),\n",
       " ('c_2_h', 'UAA'),\n",
       " ('c_2_h', 'UAL'),\n",
       " ('c_2_h', 'UDR'),\n",
       " ('c_2_h', 'UHS'),\n",
       " ('c_2_h', 'ULTA'),\n",
       " ('c_2_h', 'UNH'),\n",
       " ('c_2_h', 'UNM'),\n",
       " ('c_2_h', 'UNP'),\n",
       " ('c_2_h', 'UPS'),\n",
       " ('c_2_h', 'URI'),\n",
       " ('c_2_h', 'USB'),\n",
       " ('c_2_h', 'UTX'),\n",
       " ('c_2_h', 'V'),\n",
       " ('c_2_h', 'VAR'),\n",
       " ('c_2_h', 'VFC'),\n",
       " ('c_2_h', 'VIAB'),\n",
       " ('c_2_h', 'VLO'),\n",
       " ('c_2_h', 'VMC'),\n",
       " ('c_2_h', 'VNO'),\n",
       " ('c_2_h', 'VRSK'),\n",
       " ('c_2_h', 'VRSN'),\n",
       " ('c_2_h', 'VRTX'),\n",
       " ('c_2_h', 'VTR'),\n",
       " ('c_2_h', 'WAT'),\n",
       " ('c_2_h', 'WBA'),\n",
       " ('c_2_h', 'WEC'),\n",
       " ('c_2_h', 'WFC'),\n",
       " ('c_2_h', 'WHR'),\n",
       " ('c_2_h', 'WLTW'),\n",
       " ('c_2_h', 'WM'),\n",
       " ('c_2_h', 'WMB'),\n",
       " ('c_2_h', 'WMT'),\n",
       " ('c_2_h', 'WRK'),\n",
       " ('c_2_h', 'WU'),\n",
       " ('c_2_h', 'WY'),\n",
       " ('c_2_h', 'WYN'),\n",
       " ('c_2_h', 'WYNN'),\n",
       " ('c_2_h', 'XEC'),\n",
       " ('c_2_h', 'XEL'),\n",
       " ('c_2_h', 'XL'),\n",
       " ('c_2_h', 'XLNX'),\n",
       " ('c_2_h', 'XOM'),\n",
       " ('c_2_h', 'XRAY'),\n",
       " ('c_2_h', 'XRX'),\n",
       " ('c_2_h', 'XYL'),\n",
       " ('c_2_h', 'ZBH'),\n",
       " ('c_2_h', 'ZION'),\n",
       " ('c_2_h', 'ZTS'),\n",
       " ('c_2_o', 'A'),\n",
       " ('c_2_o', 'AAL'),\n",
       " ('c_2_o', 'AAP'),\n",
       " ('c_2_o', 'AAPL'),\n",
       " ('c_2_o', 'ABBV'),\n",
       " ('c_2_o', 'ABC'),\n",
       " ('c_2_o', 'ACN'),\n",
       " ('c_2_o', 'ADBE'),\n",
       " ('c_2_o', 'ADI'),\n",
       " ('c_2_o', 'ADM'),\n",
       " ('c_2_o', 'ADSK'),\n",
       " ('c_2_o', 'AEE'),\n",
       " ('c_2_o', 'AEP'),\n",
       " ('c_2_o', 'AES'),\n",
       " ('c_2_o', 'AET'),\n",
       " ('c_2_o', 'AFL'),\n",
       " ('c_2_o', 'AGN'),\n",
       " ('c_2_o', 'AIG'),\n",
       " ('c_2_o', 'AIV'),\n",
       " ('c_2_o', 'AIZ'),\n",
       " ('c_2_o', 'AJG'),\n",
       " ('c_2_o', 'AKAM'),\n",
       " ('c_2_o', 'ALB'),\n",
       " ('c_2_o', 'ALK'),\n",
       " ('c_2_o', 'ALL'),\n",
       " ('c_2_o', 'ALLE'),\n",
       " ('c_2_o', 'ALXN'),\n",
       " ('c_2_o', 'AMAT'),\n",
       " ('c_2_o', 'AMD'),\n",
       " ('c_2_o', 'AME'),\n",
       " ('c_2_o', 'AMG'),\n",
       " ('c_2_o', 'AMGN'),\n",
       " ('c_2_o', 'AMP'),\n",
       " ('c_2_o', 'AMT'),\n",
       " ('c_2_o', 'ANSS'),\n",
       " ('c_2_o', 'ANTM'),\n",
       " ('c_2_o', 'AON'),\n",
       " ('c_2_o', 'AOS'),\n",
       " ('c_2_o', 'APA'),\n",
       " ('c_2_o', 'APC'),\n",
       " ('c_2_o', 'APD'),\n",
       " ('c_2_o', 'APH'),\n",
       " ('c_2_o', 'ARE'),\n",
       " ('c_2_o', 'ARNC'),\n",
       " ('c_2_o', 'ATVI'),\n",
       " ('c_2_o', 'AVB'),\n",
       " ('c_2_o', 'AVGO'),\n",
       " ('c_2_o', 'AVY'),\n",
       " ('c_2_o', 'AYI'),\n",
       " ('c_2_o', 'AZO'),\n",
       " ('c_2_o', 'BA'),\n",
       " ('c_2_o', 'BAX'),\n",
       " ('c_2_o', 'BBT'),\n",
       " ('c_2_o', 'BBY'),\n",
       " ('c_2_o', 'BCR'),\n",
       " ('c_2_o', 'BDX'),\n",
       " ('c_2_o', 'BEN'),\n",
       " ('c_2_o', 'BHF'),\n",
       " ('c_2_o', 'BHGE'),\n",
       " ('c_2_o', 'BIIB'),\n",
       " ('c_2_o', 'BK'),\n",
       " ('c_2_o', 'BLL'),\n",
       " ('c_2_o', 'BMY'),\n",
       " ('c_2_o', 'BWA'),\n",
       " ('c_2_o', 'BXP'),\n",
       " ('c_2_o', 'CA'),\n",
       " ('c_2_o', 'CAH'),\n",
       " ('c_2_o', 'CB'),\n",
       " ('c_2_o', 'CBOE'),\n",
       " ('c_2_o', 'CBS'),\n",
       " ('c_2_o', 'CCI'),\n",
       " ('c_2_o', 'CDNS'),\n",
       " ('c_2_o', 'CELG'),\n",
       " ('c_2_o', 'CERN'),\n",
       " ('c_2_o', 'CF'),\n",
       " ('c_2_o', 'CHD'),\n",
       " ('c_2_o', 'CHK'),\n",
       " ('c_2_o', 'CHRW'),\n",
       " ('c_2_o', 'CHTR'),\n",
       " ('c_2_o', 'CI'),\n",
       " ('c_2_o', 'CL'),\n",
       " ('c_2_o', 'CLX'),\n",
       " ('c_2_o', 'CMA'),\n",
       " ('c_2_o', 'CMCSA'),\n",
       " ('c_2_o', 'CMG'),\n",
       " ('c_2_o', 'CMS'),\n",
       " ('c_2_o', 'CNC'),\n",
       " ('c_2_o', 'CNP'),\n",
       " ('c_2_o', 'COF'),\n",
       " ('c_2_o', 'COG'),\n",
       " ('c_2_o', 'COH'),\n",
       " ('c_2_o', 'COL'),\n",
       " ('c_2_o', 'COO'),\n",
       " ('c_2_o', 'COP'),\n",
       " ('c_2_o', 'COST'),\n",
       " ('c_2_o', 'COTY'),\n",
       " ('c_2_o', 'CPB'),\n",
       " ('c_2_o', 'CRM'),\n",
       " ('c_2_o', 'CSCO'),\n",
       " ('c_2_o', 'CSRA'),\n",
       " ('c_2_o', 'CSX'),\n",
       " ('c_2_o', 'CTAS'),\n",
       " ('c_2_o', 'CTL'),\n",
       " ('c_2_o', 'CTSH'),\n",
       " ('c_2_o', 'CTXS'),\n",
       " ('c_2_o', 'CVS'),\n",
       " ('c_2_o', 'CVX'),\n",
       " ('c_2_o', 'D'),\n",
       " ('c_2_o', 'DAL'),\n",
       " ('c_2_o', 'DE'),\n",
       " ('c_2_o', 'DFS'),\n",
       " ('c_2_o', 'DG'),\n",
       " ('c_2_o', 'DGX'),\n",
       " ('c_2_o', 'DHI'),\n",
       " ('c_2_o', 'DHR'),\n",
       " ('c_2_o', 'DISCA'),\n",
       " ('c_2_o', 'DISCK'),\n",
       " ('c_2_o', 'DLPH'),\n",
       " ('c_2_o', 'DLR'),\n",
       " ('c_2_o', 'DLTR'),\n",
       " ('c_2_o', 'DOV'),\n",
       " ('c_2_o', 'DPS'),\n",
       " ('c_2_o', 'DRE'),\n",
       " ('c_2_o', 'DRI'),\n",
       " ('c_2_o', 'DUK'),\n",
       " ('c_2_o', 'DVN'),\n",
       " ('c_2_o', 'DWDP'),\n",
       " ('c_2_o', 'DXC'),\n",
       " ('c_2_o', 'EA'),\n",
       " ('c_2_o', 'ECL'),\n",
       " ('c_2_o', 'EFX'),\n",
       " ('c_2_o', 'EL'),\n",
       " ('c_2_o', 'EMN'),\n",
       " ('c_2_o', 'EMR'),\n",
       " ('c_2_o', 'EOG'),\n",
       " ('c_2_o', 'EQIX'),\n",
       " ('c_2_o', 'EQR'),\n",
       " ('c_2_o', 'EQT'),\n",
       " ('c_2_o', 'ES'),\n",
       " ('c_2_o', 'ESS'),\n",
       " ('c_2_o', 'ETFC'),\n",
       " ('c_2_o', 'ETN'),\n",
       " ('c_2_o', 'ETR'),\n",
       " ('c_2_o', 'EVHC'),\n",
       " ('c_2_o', 'EW'),\n",
       " ('c_2_o', 'EXC'),\n",
       " ('c_2_o', 'EXPD'),\n",
       " ('c_2_o', 'EXPE'),\n",
       " ('c_2_o', 'EXR'),\n",
       " ('c_2_o', 'F'),\n",
       " ('c_2_o', 'FAST'),\n",
       " ('c_2_o', 'FB'),\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = P.columns.tolist()\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A_c1_c0', 'AAL_c1_c0', 'AAP_c1_c0', 'AAPL_c1_c0', 'ABBV_c1_c0',\n",
       "       'ABC_c1_c0', 'ACN_c1_c0', 'ADBE_c1_c0', 'ADI_c1_c0', 'ADM_c1_c0',\n",
       "       ...\n",
       "       'XEL_vol', 'XL_vol', 'XLNX_vol', 'XOM_vol', 'XRAY_vol', 'XRX_vol',\n",
       "       'XYL_vol', 'ZBH_vol', 'ZION_vol', 'ZTS_vol'],\n",
       "      dtype='object', length=2968)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ind = pd.Index(e[1] +'_' + e[0] for e in mi)\n",
    "new_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_c1_c0</th>\n",
       "      <th>AAL_c1_c0</th>\n",
       "      <th>AAP_c1_c0</th>\n",
       "      <th>AAPL_c1_c0</th>\n",
       "      <th>ABBV_c1_c0</th>\n",
       "      <th>ABC_c1_c0</th>\n",
       "      <th>ACN_c1_c0</th>\n",
       "      <th>ADBE_c1_c0</th>\n",
       "      <th>ADI_c1_c0</th>\n",
       "      <th>ADM_c1_c0</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL_vol</th>\n",
       "      <th>XL_vol</th>\n",
       "      <th>XLNX_vol</th>\n",
       "      <th>XOM_vol</th>\n",
       "      <th>XRAY_vol</th>\n",
       "      <th>XRX_vol</th>\n",
       "      <th>XYL_vol</th>\n",
       "      <th>ZBH_vol</th>\n",
       "      <th>ZION_vol</th>\n",
       "      <th>ZTS_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>-0.009967</td>\n",
       "      <td>-0.046091</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>-0.017343</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.015262</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871786</td>\n",
       "      <td>-0.393039</td>\n",
       "      <td>0.682807</td>\n",
       "      <td>0.311627</td>\n",
       "      <td>-0.260591</td>\n",
       "      <td>-0.753432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.231260</td>\n",
       "      <td>-0.690485</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>-0.033096</td>\n",
       "      <td>-0.024673</td>\n",
       "      <td>-0.061960</td>\n",
       "      <td>-0.079406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023021</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>-0.034818</td>\n",
       "      <td>-0.026424</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.989941</td>\n",
       "      <td>-0.504889</td>\n",
       "      <td>-0.400928</td>\n",
       "      <td>-0.047999</td>\n",
       "      <td>-0.547116</td>\n",
       "      <td>-0.889366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.142855</td>\n",
       "      <td>-0.857160</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>0.016261</td>\n",
       "      <td>-0.014611</td>\n",
       "      <td>0.044147</td>\n",
       "      <td>-0.013476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013155</td>\n",
       "      <td>-0.027296</td>\n",
       "      <td>-0.002978</td>\n",
       "      <td>-0.012783</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365741</td>\n",
       "      <td>-0.536379</td>\n",
       "      <td>0.599084</td>\n",
       "      <td>0.429950</td>\n",
       "      <td>-0.288010</td>\n",
       "      <td>-0.852734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557788</td>\n",
       "      <td>-0.697810</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>-0.001416</td>\n",
       "      <td>-0.105088</td>\n",
       "      <td>-0.052876</td>\n",
       "      <td>-0.036635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025675</td>\n",
       "      <td>-0.033590</td>\n",
       "      <td>-0.018486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540284</td>\n",
       "      <td>-0.271225</td>\n",
       "      <td>0.036374</td>\n",
       "      <td>0.790889</td>\n",
       "      <td>-0.302766</td>\n",
       "      <td>-0.672058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006898</td>\n",
       "      <td>-0.411987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>0.002547</td>\n",
       "      <td>-0.010959</td>\n",
       "      <td>-0.015102</td>\n",
       "      <td>0.046493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>-0.004721</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351571</td>\n",
       "      <td>-0.257501</td>\n",
       "      <td>1.300453</td>\n",
       "      <td>0.175424</td>\n",
       "      <td>0.278874</td>\n",
       "      <td>-0.832352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.827988</td>\n",
       "      <td>-0.153840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2968 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A_c1_c0  AAL_c1_c0  AAP_c1_c0  AAPL_c1_c0  ABBV_c1_c0  ABC_c1_c0  \\\n",
       "Date                                                                            \n",
       "2008-01-02 -0.009967  -0.046091   0.009531    0.000462         NaN   0.006042   \n",
       "2008-01-03 -0.033096  -0.024673  -0.061960   -0.079406         NaN  -0.023021   \n",
       "2008-01-04  0.016261  -0.014611   0.044147   -0.013476         NaN   0.013155   \n",
       "2008-01-07 -0.001416  -0.105088  -0.052876   -0.036635         NaN   0.028215   \n",
       "2008-01-08  0.002547  -0.010959  -0.015102    0.046493         NaN   0.008941   \n",
       "\n",
       "            ACN_c1_c0  ADBE_c1_c0  ADI_c1_c0  ADM_c1_c0   ...      XEL_vol  \\\n",
       "Date                                                      ...                \n",
       "2008-01-02  -0.017343    0.001916  -0.015262   0.010331   ...    -0.871786   \n",
       "2008-01-03  -0.015068   -0.034818  -0.026424   0.002621   ...    -0.989941   \n",
       "2008-01-04  -0.027296   -0.002978  -0.012783   0.000218   ...    -0.365741   \n",
       "2008-01-07   0.000000   -0.025675  -0.033590  -0.018486   ...    -0.540284   \n",
       "2008-01-08  -0.004721    0.006101  -0.014123   0.003769   ...    -0.351571   \n",
       "\n",
       "              XL_vol  XLNX_vol   XOM_vol  XRAY_vol   XRX_vol  XYL_vol  \\\n",
       "Date                                                                    \n",
       "2008-01-02 -0.393039  0.682807  0.311627 -0.260591 -0.753432      NaN   \n",
       "2008-01-03 -0.504889 -0.400928 -0.047999 -0.547116 -0.889366      NaN   \n",
       "2008-01-04 -0.536379  0.599084  0.429950 -0.288010 -0.852734      NaN   \n",
       "2008-01-07 -0.271225  0.036374  0.790889 -0.302766 -0.672058      NaN   \n",
       "2008-01-08 -0.257501  1.300453  0.175424  0.278874 -0.832352      NaN   \n",
       "\n",
       "             ZBH_vol  ZION_vol  ZTS_vol  \n",
       "Date                                     \n",
       "2008-01-02 -0.231260 -0.690485      NaN  \n",
       "2008-01-03 -0.142855 -0.857160      NaN  \n",
       "2008-01-04  0.557788 -0.697810      NaN  \n",
       "2008-01-07  1.006898 -0.411987      NaN  \n",
       "2008-01-08  2.827988 -0.153840      NaN  \n",
       "\n",
       "[5 rows x 2968 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.columns = new_ind\n",
    "#P = P.sort_values(by=new_ind) # Sort by columns -- what is the purpose of this?\n",
    "P.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2267, 2610)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_flat = P.dropna(1)\n",
    "clean_and_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_cols = list(filter(lambda x: 'c1_c0' in x, clean_and_flat.columns.values))\n",
    "input_cols  = list(filter(lambda x: 'c1_c0' not in x, clean_and_flat.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A_c_2_h',\n",
       " 'AAL_c_2_h',\n",
       " 'AAP_c_2_h',\n",
       " 'AAPL_c_2_h',\n",
       " 'ABC_c_2_h',\n",
       " 'ACN_c_2_h',\n",
       " 'ADBE_c_2_h',\n",
       " 'ADI_c_2_h',\n",
       " 'ADM_c_2_h',\n",
       " 'ADSK_c_2_h',\n",
       " 'AEE_c_2_h',\n",
       " 'AEP_c_2_h',\n",
       " 'AES_c_2_h',\n",
       " 'AET_c_2_h',\n",
       " 'AFL_c_2_h',\n",
       " 'AGN_c_2_h',\n",
       " 'AIG_c_2_h',\n",
       " 'AIV_c_2_h',\n",
       " 'AIZ_c_2_h',\n",
       " 'AJG_c_2_h',\n",
       " 'AKAM_c_2_h',\n",
       " 'ALB_c_2_h',\n",
       " 'ALK_c_2_h',\n",
       " 'ALL_c_2_h',\n",
       " 'ALXN_c_2_h',\n",
       " 'AMAT_c_2_h',\n",
       " 'AMD_c_2_h',\n",
       " 'AME_c_2_h',\n",
       " 'AMG_c_2_h',\n",
       " 'AMGN_c_2_h',\n",
       " 'AMP_c_2_h',\n",
       " 'AMT_c_2_h',\n",
       " 'ANSS_c_2_h',\n",
       " 'ANTM_c_2_h',\n",
       " 'AON_c_2_h',\n",
       " 'APA_c_2_h',\n",
       " 'APC_c_2_h',\n",
       " 'APD_c_2_h',\n",
       " 'APH_c_2_h',\n",
       " 'ARE_c_2_h',\n",
       " 'ARNC_c_2_h',\n",
       " 'ATVI_c_2_h',\n",
       " 'AVB_c_2_h',\n",
       " 'AVY_c_2_h',\n",
       " 'AYI_c_2_h',\n",
       " 'AZO_c_2_h',\n",
       " 'BA_c_2_h',\n",
       " 'BAX_c_2_h',\n",
       " 'BBT_c_2_h',\n",
       " 'BCR_c_2_h',\n",
       " 'BDX_c_2_h',\n",
       " 'BEN_c_2_h',\n",
       " 'BHGE_c_2_h',\n",
       " 'BIIB_c_2_h',\n",
       " 'BK_c_2_h',\n",
       " 'BLL_c_2_h',\n",
       " 'BMY_c_2_h',\n",
       " 'BWA_c_2_h',\n",
       " 'BXP_c_2_h',\n",
       " 'CA_c_2_h',\n",
       " 'CAH_c_2_h',\n",
       " 'CB_c_2_h',\n",
       " 'CBS_c_2_h',\n",
       " 'CCI_c_2_h',\n",
       " 'CDNS_c_2_h',\n",
       " 'CELG_c_2_h',\n",
       " 'CERN_c_2_h',\n",
       " 'CF_c_2_h',\n",
       " 'CHK_c_2_h',\n",
       " 'CHRW_c_2_h',\n",
       " 'CI_c_2_h',\n",
       " 'CL_c_2_h',\n",
       " 'CLX_c_2_h',\n",
       " 'CMA_c_2_h',\n",
       " 'CMCSA_c_2_h',\n",
       " 'CMG_c_2_h',\n",
       " 'CMS_c_2_h',\n",
       " 'CNC_c_2_h',\n",
       " 'CNP_c_2_h',\n",
       " 'COF_c_2_h',\n",
       " 'COG_c_2_h',\n",
       " 'COH_c_2_h',\n",
       " 'COL_c_2_h',\n",
       " 'COO_c_2_h',\n",
       " 'COST_c_2_h',\n",
       " 'CPB_c_2_h',\n",
       " 'CRM_c_2_h',\n",
       " 'CSCO_c_2_h',\n",
       " 'CSX_c_2_h',\n",
       " 'CTAS_c_2_h',\n",
       " 'CTL_c_2_h',\n",
       " 'CTSH_c_2_h',\n",
       " 'CTXS_c_2_h',\n",
       " 'CVS_c_2_h',\n",
       " 'CVX_c_2_h',\n",
       " 'D_c_2_h',\n",
       " 'DAL_c_2_h',\n",
       " 'DE_c_2_h',\n",
       " 'DFS_c_2_h',\n",
       " 'DGX_c_2_h',\n",
       " 'DHR_c_2_h',\n",
       " 'DISCA_c_2_h',\n",
       " 'DLR_c_2_h',\n",
       " 'DLTR_c_2_h',\n",
       " 'DOV_c_2_h',\n",
       " 'DRE_c_2_h',\n",
       " 'DRI_c_2_h',\n",
       " 'DUK_c_2_h',\n",
       " 'DVN_c_2_h',\n",
       " 'DWDP_c_2_h',\n",
       " 'DXC_c_2_h',\n",
       " 'EA_c_2_h',\n",
       " 'ECL_c_2_h',\n",
       " 'EFX_c_2_h',\n",
       " 'EL_c_2_h',\n",
       " 'EMN_c_2_h',\n",
       " 'EMR_c_2_h',\n",
       " 'EOG_c_2_h',\n",
       " 'EQIX_c_2_h',\n",
       " 'EQR_c_2_h',\n",
       " 'EQT_c_2_h',\n",
       " 'ES_c_2_h',\n",
       " 'ESS_c_2_h',\n",
       " 'ETFC_c_2_h',\n",
       " 'ETN_c_2_h',\n",
       " 'ETR_c_2_h',\n",
       " 'EW_c_2_h',\n",
       " 'EXC_c_2_h',\n",
       " 'EXPD_c_2_h',\n",
       " 'EXPE_c_2_h',\n",
       " 'EXR_c_2_h',\n",
       " 'F_c_2_h',\n",
       " 'FAST_c_2_h',\n",
       " 'FCX_c_2_h',\n",
       " 'FDX_c_2_h',\n",
       " 'FE_c_2_h',\n",
       " 'FFIV_c_2_h',\n",
       " 'FIS_c_2_h',\n",
       " 'FISV_c_2_h',\n",
       " 'FITB_c_2_h',\n",
       " 'FL_c_2_h',\n",
       " 'FLIR_c_2_h',\n",
       " 'FLR_c_2_h',\n",
       " 'FLS_c_2_h',\n",
       " 'FMC_c_2_h',\n",
       " 'FOX_c_2_h',\n",
       " 'FRT_c_2_h',\n",
       " 'FTI_c_2_h',\n",
       " 'GD_c_2_h',\n",
       " 'GE_c_2_h',\n",
       " 'GILD_c_2_h',\n",
       " 'GIS_c_2_h',\n",
       " 'GLW_c_2_h',\n",
       " 'GOOG_c_2_h',\n",
       " 'GOOGL_c_2_h',\n",
       " 'GPC_c_2_h',\n",
       " 'GPS_c_2_h',\n",
       " 'GRMN_c_2_h',\n",
       " 'GS_c_2_h',\n",
       " 'GT_c_2_h',\n",
       " 'HAL_c_2_h',\n",
       " 'HAS_c_2_h',\n",
       " 'HBAN_c_2_h',\n",
       " 'HBI_c_2_h',\n",
       " 'HCN_c_2_h',\n",
       " 'HCP_c_2_h',\n",
       " 'HES_c_2_h',\n",
       " 'HIG_c_2_h',\n",
       " 'HOLX_c_2_h',\n",
       " 'HON_c_2_h',\n",
       " 'HP_c_2_h',\n",
       " 'HRB_c_2_h',\n",
       " 'HRL_c_2_h',\n",
       " 'HRS_c_2_h',\n",
       " 'HSIC_c_2_h',\n",
       " 'HST_c_2_h',\n",
       " 'HSY_c_2_h',\n",
       " 'HUM_c_2_h',\n",
       " 'IBM_c_2_h',\n",
       " 'ICE_c_2_h',\n",
       " 'IDXX_c_2_h',\n",
       " 'IFF_c_2_h',\n",
       " 'ILMN_c_2_h',\n",
       " 'INCY_c_2_h',\n",
       " 'INTC_c_2_h',\n",
       " 'INTU_c_2_h',\n",
       " 'IP_c_2_h',\n",
       " 'IPG_c_2_h',\n",
       " 'IR_c_2_h',\n",
       " 'IRM_c_2_h',\n",
       " 'ISRG_c_2_h',\n",
       " 'IT_c_2_h',\n",
       " 'IVZ_c_2_h',\n",
       " 'JBHT_c_2_h',\n",
       " 'JCI_c_2_h',\n",
       " 'JEC_c_2_h',\n",
       " 'JNPR_c_2_h',\n",
       " 'JWN_c_2_h',\n",
       " 'KMB_c_2_h',\n",
       " 'KMX_c_2_h',\n",
       " 'KO_c_2_h',\n",
       " 'KR_c_2_h',\n",
       " 'KSU_c_2_h',\n",
       " 'L_c_2_h',\n",
       " 'LEN_c_2_h',\n",
       " 'LH_c_2_h',\n",
       " 'LKQ_c_2_h',\n",
       " 'LLY_c_2_h',\n",
       " 'LMT_c_2_h',\n",
       " 'LNT_c_2_h',\n",
       " 'LOW_c_2_h',\n",
       " 'LUK_c_2_h',\n",
       " 'LUV_c_2_h',\n",
       " 'M_c_2_h',\n",
       " 'MA_c_2_h',\n",
       " 'MAA_c_2_h',\n",
       " 'MAC_c_2_h',\n",
       " 'MAR_c_2_h',\n",
       " 'MAS_c_2_h',\n",
       " 'MAT_c_2_h',\n",
       " 'MCD_c_2_h',\n",
       " 'MCK_c_2_h',\n",
       " 'MDLZ_c_2_h',\n",
       " 'MDT_c_2_h',\n",
       " 'MET_c_2_h',\n",
       " 'MGM_c_2_h',\n",
       " 'MHK_c_2_h',\n",
       " 'MKC_c_2_h',\n",
       " 'MMC_c_2_h',\n",
       " 'MNST_c_2_h',\n",
       " 'MO_c_2_h',\n",
       " 'MOS_c_2_h',\n",
       " 'MRK_c_2_h',\n",
       " 'MRO_c_2_h',\n",
       " 'MS_c_2_h',\n",
       " 'MSFT_c_2_h',\n",
       " 'MSI_c_2_h',\n",
       " 'MTB_c_2_h',\n",
       " 'MU_c_2_h',\n",
       " 'MYL_c_2_h',\n",
       " 'NBL_c_2_h',\n",
       " 'NEE_c_2_h',\n",
       " 'NFLX_c_2_h',\n",
       " 'NI_c_2_h',\n",
       " 'NKE_c_2_h',\n",
       " 'NOC_c_2_h',\n",
       " 'NOV_c_2_h',\n",
       " 'NRG_c_2_h',\n",
       " 'NSC_c_2_h',\n",
       " 'NTAP_c_2_h',\n",
       " 'NTRS_c_2_h',\n",
       " 'NUE_c_2_h',\n",
       " 'NVDA_c_2_h',\n",
       " 'NWL_c_2_h',\n",
       " 'OKE_c_2_h',\n",
       " 'OMC_c_2_h',\n",
       " 'ORLY_c_2_h',\n",
       " 'OXY_c_2_h',\n",
       " 'PAYX_c_2_h',\n",
       " 'PBCT_c_2_h',\n",
       " 'PCAR_c_2_h',\n",
       " 'PCG_c_2_h',\n",
       " 'PCLN_c_2_h',\n",
       " 'PDCO_c_2_h',\n",
       " 'PEG_c_2_h',\n",
       " 'PEP_c_2_h',\n",
       " 'PFE_c_2_h',\n",
       " 'PFG_c_2_h',\n",
       " 'PG_c_2_h',\n",
       " 'PH_c_2_h',\n",
       " 'PHM_c_2_h',\n",
       " 'PKG_c_2_h',\n",
       " 'PKI_c_2_h',\n",
       " 'PNC_c_2_h',\n",
       " 'PNR_c_2_h',\n",
       " 'PPG_c_2_h',\n",
       " 'PPL_c_2_h',\n",
       " 'PRGO_c_2_h',\n",
       " 'PRU_c_2_h',\n",
       " 'PSA_c_2_h',\n",
       " 'PWR_c_2_h',\n",
       " 'PX_c_2_h',\n",
       " 'PXD_c_2_h',\n",
       " 'QCOM_c_2_h',\n",
       " 'RCL_c_2_h',\n",
       " 'REG_c_2_h',\n",
       " 'REGN_c_2_h',\n",
       " 'RF_c_2_h',\n",
       " 'RHT_c_2_h',\n",
       " 'RJF_c_2_h',\n",
       " 'RL_c_2_h',\n",
       " 'RMD_c_2_h',\n",
       " 'ROK_c_2_h',\n",
       " 'ROP_c_2_h',\n",
       " 'ROST_c_2_h',\n",
       " 'RRC_c_2_h',\n",
       " 'RSG_c_2_h',\n",
       " 'RTN_c_2_h',\n",
       " 'SBUX_c_2_h',\n",
       " 'SCG_c_2_h',\n",
       " 'SCHW_c_2_h',\n",
       " 'SEE_c_2_h',\n",
       " 'SHW_c_2_h',\n",
       " 'SIG_c_2_h',\n",
       " 'SJM_c_2_h',\n",
       " 'SLG_c_2_h',\n",
       " 'SNPS_c_2_h',\n",
       " 'SO_c_2_h',\n",
       " 'SRCL_c_2_h',\n",
       " 'SRE_c_2_h',\n",
       " 'STI_c_2_h',\n",
       " 'STT_c_2_h',\n",
       " 'STX_c_2_h',\n",
       " 'SWK_c_2_h',\n",
       " 'SYMC_c_2_h',\n",
       " 'SYY_c_2_h',\n",
       " 'T_c_2_h',\n",
       " 'TEL_c_2_h',\n",
       " 'TGT_c_2_h',\n",
       " 'TJX_c_2_h',\n",
       " 'TMK_c_2_h',\n",
       " 'TMO_c_2_h',\n",
       " 'TROW_c_2_h',\n",
       " 'TRV_c_2_h',\n",
       " 'TSCO_c_2_h',\n",
       " 'TWX_c_2_h',\n",
       " 'TXN_c_2_h',\n",
       " 'TXT_c_2_h',\n",
       " 'UAA_c_2_h',\n",
       " 'UAL_c_2_h',\n",
       " 'UDR_c_2_h',\n",
       " 'UHS_c_2_h',\n",
       " 'ULTA_c_2_h',\n",
       " 'UNH_c_2_h',\n",
       " 'UNM_c_2_h',\n",
       " 'UNP_c_2_h',\n",
       " 'UPS_c_2_h',\n",
       " 'URI_c_2_h',\n",
       " 'USB_c_2_h',\n",
       " 'UTX_c_2_h',\n",
       " 'VAR_c_2_h',\n",
       " 'VFC_c_2_h',\n",
       " 'VIAB_c_2_h',\n",
       " 'VLO_c_2_h',\n",
       " 'VMC_c_2_h',\n",
       " 'VNO_c_2_h',\n",
       " 'VRSN_c_2_h',\n",
       " 'VRTX_c_2_h',\n",
       " 'VTR_c_2_h',\n",
       " 'WAT_c_2_h',\n",
       " 'WBA_c_2_h',\n",
       " 'WEC_c_2_h',\n",
       " 'WFC_c_2_h',\n",
       " 'WHR_c_2_h',\n",
       " 'WLTW_c_2_h',\n",
       " 'WM_c_2_h',\n",
       " 'WMB_c_2_h',\n",
       " 'WMT_c_2_h',\n",
       " 'WU_c_2_h',\n",
       " 'WY_c_2_h',\n",
       " 'WYN_c_2_h',\n",
       " 'WYNN_c_2_h',\n",
       " 'XEC_c_2_h',\n",
       " 'XEL_c_2_h',\n",
       " 'XL_c_2_h',\n",
       " 'XLNX_c_2_h',\n",
       " 'XOM_c_2_h',\n",
       " 'XRAY_c_2_h',\n",
       " 'XRX_c_2_h',\n",
       " 'ZBH_c_2_h',\n",
       " 'ZION_c_2_h',\n",
       " 'A_c_2_o',\n",
       " 'AAL_c_2_o',\n",
       " 'AAP_c_2_o',\n",
       " 'AAPL_c_2_o',\n",
       " 'ABC_c_2_o',\n",
       " 'ACN_c_2_o',\n",
       " 'ADBE_c_2_o',\n",
       " 'ADI_c_2_o',\n",
       " 'ADM_c_2_o',\n",
       " 'ADSK_c_2_o',\n",
       " 'AEE_c_2_o',\n",
       " 'AEP_c_2_o',\n",
       " 'AES_c_2_o',\n",
       " 'AET_c_2_o',\n",
       " 'AFL_c_2_o',\n",
       " 'AGN_c_2_o',\n",
       " 'AIG_c_2_o',\n",
       " 'AIV_c_2_o',\n",
       " 'AIZ_c_2_o',\n",
       " 'AJG_c_2_o',\n",
       " 'AKAM_c_2_o',\n",
       " 'ALB_c_2_o',\n",
       " 'ALK_c_2_o',\n",
       " 'ALL_c_2_o',\n",
       " 'ALXN_c_2_o',\n",
       " 'AMAT_c_2_o',\n",
       " 'AMD_c_2_o',\n",
       " 'AME_c_2_o',\n",
       " 'AMG_c_2_o',\n",
       " 'AMGN_c_2_o',\n",
       " 'AMP_c_2_o',\n",
       " 'AMT_c_2_o',\n",
       " 'ANSS_c_2_o',\n",
       " 'ANTM_c_2_o',\n",
       " 'AON_c_2_o',\n",
       " 'APA_c_2_o',\n",
       " 'APC_c_2_o',\n",
       " 'APD_c_2_o',\n",
       " 'APH_c_2_o',\n",
       " 'ARE_c_2_o',\n",
       " 'ARNC_c_2_o',\n",
       " 'ATVI_c_2_o',\n",
       " 'AVB_c_2_o',\n",
       " 'AVY_c_2_o',\n",
       " 'AYI_c_2_o',\n",
       " 'AZO_c_2_o',\n",
       " 'BA_c_2_o',\n",
       " 'BAX_c_2_o',\n",
       " 'BBT_c_2_o',\n",
       " 'BCR_c_2_o',\n",
       " 'BDX_c_2_o',\n",
       " 'BEN_c_2_o',\n",
       " 'BHGE_c_2_o',\n",
       " 'BIIB_c_2_o',\n",
       " 'BK_c_2_o',\n",
       " 'BLL_c_2_o',\n",
       " 'BMY_c_2_o',\n",
       " 'BWA_c_2_o',\n",
       " 'BXP_c_2_o',\n",
       " 'CA_c_2_o',\n",
       " 'CAH_c_2_o',\n",
       " 'CB_c_2_o',\n",
       " 'CBS_c_2_o',\n",
       " 'CCI_c_2_o',\n",
       " 'CDNS_c_2_o',\n",
       " 'CELG_c_2_o',\n",
       " 'CERN_c_2_o',\n",
       " 'CF_c_2_o',\n",
       " 'CHK_c_2_o',\n",
       " 'CHRW_c_2_o',\n",
       " 'CI_c_2_o',\n",
       " 'CL_c_2_o',\n",
       " 'CLX_c_2_o',\n",
       " 'CMA_c_2_o',\n",
       " 'CMCSA_c_2_o',\n",
       " 'CMG_c_2_o',\n",
       " 'CMS_c_2_o',\n",
       " 'CNC_c_2_o',\n",
       " 'CNP_c_2_o',\n",
       " 'COF_c_2_o',\n",
       " 'COG_c_2_o',\n",
       " 'COH_c_2_o',\n",
       " 'COL_c_2_o',\n",
       " 'COO_c_2_o',\n",
       " 'COST_c_2_o',\n",
       " 'CPB_c_2_o',\n",
       " 'CRM_c_2_o',\n",
       " 'CSCO_c_2_o',\n",
       " 'CSX_c_2_o',\n",
       " 'CTAS_c_2_o',\n",
       " 'CTL_c_2_o',\n",
       " 'CTSH_c_2_o',\n",
       " 'CTXS_c_2_o',\n",
       " 'CVS_c_2_o',\n",
       " 'CVX_c_2_o',\n",
       " 'D_c_2_o',\n",
       " 'DAL_c_2_o',\n",
       " 'DE_c_2_o',\n",
       " 'DFS_c_2_o',\n",
       " 'DGX_c_2_o',\n",
       " 'DHR_c_2_o',\n",
       " 'DISCA_c_2_o',\n",
       " 'DLR_c_2_o',\n",
       " 'DLTR_c_2_o',\n",
       " 'DOV_c_2_o',\n",
       " 'DRE_c_2_o',\n",
       " 'DRI_c_2_o',\n",
       " 'DUK_c_2_o',\n",
       " 'DVN_c_2_o',\n",
       " 'DWDP_c_2_o',\n",
       " 'DXC_c_2_o',\n",
       " 'EA_c_2_o',\n",
       " 'ECL_c_2_o',\n",
       " 'EFX_c_2_o',\n",
       " 'EL_c_2_o',\n",
       " 'EMN_c_2_o',\n",
       " 'EMR_c_2_o',\n",
       " 'EOG_c_2_o',\n",
       " 'EQIX_c_2_o',\n",
       " 'EQR_c_2_o',\n",
       " 'EQT_c_2_o',\n",
       " 'ES_c_2_o',\n",
       " 'ESS_c_2_o',\n",
       " 'ETFC_c_2_o',\n",
       " 'ETN_c_2_o',\n",
       " 'ETR_c_2_o',\n",
       " 'EW_c_2_o',\n",
       " 'EXC_c_2_o',\n",
       " 'EXPD_c_2_o',\n",
       " 'EXPE_c_2_o',\n",
       " 'EXR_c_2_o',\n",
       " 'F_c_2_o',\n",
       " 'FAST_c_2_o',\n",
       " 'FCX_c_2_o',\n",
       " 'FDX_c_2_o',\n",
       " 'FE_c_2_o',\n",
       " 'FFIV_c_2_o',\n",
       " 'FIS_c_2_o',\n",
       " 'FISV_c_2_o',\n",
       " 'FITB_c_2_o',\n",
       " 'FL_c_2_o',\n",
       " 'FLIR_c_2_o',\n",
       " 'FLR_c_2_o',\n",
       " 'FLS_c_2_o',\n",
       " 'FMC_c_2_o',\n",
       " 'FOX_c_2_o',\n",
       " 'FRT_c_2_o',\n",
       " 'FTI_c_2_o',\n",
       " 'GD_c_2_o',\n",
       " 'GE_c_2_o',\n",
       " 'GILD_c_2_o',\n",
       " 'GIS_c_2_o',\n",
       " 'GLW_c_2_o',\n",
       " 'GOOG_c_2_o',\n",
       " 'GOOGL_c_2_o',\n",
       " 'GPC_c_2_o',\n",
       " 'GPS_c_2_o',\n",
       " 'GRMN_c_2_o',\n",
       " 'GS_c_2_o',\n",
       " 'GT_c_2_o',\n",
       " 'HAL_c_2_o',\n",
       " 'HAS_c_2_o',\n",
       " 'HBAN_c_2_o',\n",
       " 'HBI_c_2_o',\n",
       " 'HCN_c_2_o',\n",
       " 'HCP_c_2_o',\n",
       " 'HES_c_2_o',\n",
       " 'HIG_c_2_o',\n",
       " 'HOLX_c_2_o',\n",
       " 'HON_c_2_o',\n",
       " 'HP_c_2_o',\n",
       " 'HRB_c_2_o',\n",
       " 'HRL_c_2_o',\n",
       " 'HRS_c_2_o',\n",
       " 'HSIC_c_2_o',\n",
       " 'HST_c_2_o',\n",
       " 'HSY_c_2_o',\n",
       " 'HUM_c_2_o',\n",
       " 'IBM_c_2_o',\n",
       " 'ICE_c_2_o',\n",
       " 'IDXX_c_2_o',\n",
       " 'IFF_c_2_o',\n",
       " 'ILMN_c_2_o',\n",
       " 'INCY_c_2_o',\n",
       " 'INTC_c_2_o',\n",
       " 'INTU_c_2_o',\n",
       " 'IP_c_2_o',\n",
       " 'IPG_c_2_o',\n",
       " 'IR_c_2_o',\n",
       " 'IRM_c_2_o',\n",
       " 'ISRG_c_2_o',\n",
       " 'IT_c_2_o',\n",
       " 'IVZ_c_2_o',\n",
       " 'JBHT_c_2_o',\n",
       " 'JCI_c_2_o',\n",
       " 'JEC_c_2_o',\n",
       " 'JNPR_c_2_o',\n",
       " 'JWN_c_2_o',\n",
       " 'KMB_c_2_o',\n",
       " 'KMX_c_2_o',\n",
       " 'KO_c_2_o',\n",
       " 'KR_c_2_o',\n",
       " 'KSU_c_2_o',\n",
       " 'L_c_2_o',\n",
       " 'LEN_c_2_o',\n",
       " 'LH_c_2_o',\n",
       " 'LKQ_c_2_o',\n",
       " 'LLY_c_2_o',\n",
       " 'LMT_c_2_o',\n",
       " 'LNT_c_2_o',\n",
       " 'LOW_c_2_o',\n",
       " 'LUK_c_2_o',\n",
       " 'LUV_c_2_o',\n",
       " 'M_c_2_o',\n",
       " 'MA_c_2_o',\n",
       " 'MAA_c_2_o',\n",
       " 'MAC_c_2_o',\n",
       " 'MAR_c_2_o',\n",
       " 'MAS_c_2_o',\n",
       " 'MAT_c_2_o',\n",
       " 'MCD_c_2_o',\n",
       " 'MCK_c_2_o',\n",
       " 'MDLZ_c_2_o',\n",
       " 'MDT_c_2_o',\n",
       " 'MET_c_2_o',\n",
       " 'MGM_c_2_o',\n",
       " 'MHK_c_2_o',\n",
       " 'MKC_c_2_o',\n",
       " 'MMC_c_2_o',\n",
       " 'MNST_c_2_o',\n",
       " 'MO_c_2_o',\n",
       " 'MOS_c_2_o',\n",
       " 'MRK_c_2_o',\n",
       " 'MRO_c_2_o',\n",
       " 'MS_c_2_o',\n",
       " 'MSFT_c_2_o',\n",
       " 'MSI_c_2_o',\n",
       " 'MTB_c_2_o',\n",
       " 'MU_c_2_o',\n",
       " 'MYL_c_2_o',\n",
       " 'NBL_c_2_o',\n",
       " 'NEE_c_2_o',\n",
       " 'NFLX_c_2_o',\n",
       " 'NI_c_2_o',\n",
       " 'NKE_c_2_o',\n",
       " 'NOC_c_2_o',\n",
       " 'NOV_c_2_o',\n",
       " 'NRG_c_2_o',\n",
       " 'NSC_c_2_o',\n",
       " 'NTAP_c_2_o',\n",
       " 'NTRS_c_2_o',\n",
       " 'NUE_c_2_o',\n",
       " 'NVDA_c_2_o',\n",
       " 'NWL_c_2_o',\n",
       " 'OKE_c_2_o',\n",
       " 'OMC_c_2_o',\n",
       " 'ORLY_c_2_o',\n",
       " 'OXY_c_2_o',\n",
       " 'PAYX_c_2_o',\n",
       " 'PBCT_c_2_o',\n",
       " 'PCAR_c_2_o',\n",
       " 'PCG_c_2_o',\n",
       " 'PCLN_c_2_o',\n",
       " 'PDCO_c_2_o',\n",
       " 'PEG_c_2_o',\n",
       " 'PEP_c_2_o',\n",
       " 'PFE_c_2_o',\n",
       " 'PFG_c_2_o',\n",
       " 'PG_c_2_o',\n",
       " 'PH_c_2_o',\n",
       " 'PHM_c_2_o',\n",
       " 'PKG_c_2_o',\n",
       " 'PKI_c_2_o',\n",
       " 'PNC_c_2_o',\n",
       " 'PNR_c_2_o',\n",
       " 'PPG_c_2_o',\n",
       " 'PPL_c_2_o',\n",
       " 'PRGO_c_2_o',\n",
       " 'PRU_c_2_o',\n",
       " 'PSA_c_2_o',\n",
       " 'PWR_c_2_o',\n",
       " 'PX_c_2_o',\n",
       " 'PXD_c_2_o',\n",
       " 'QCOM_c_2_o',\n",
       " 'RCL_c_2_o',\n",
       " 'REG_c_2_o',\n",
       " 'REGN_c_2_o',\n",
       " 'RF_c_2_o',\n",
       " 'RHT_c_2_o',\n",
       " 'RJF_c_2_o',\n",
       " 'RL_c_2_o',\n",
       " 'RMD_c_2_o',\n",
       " 'ROK_c_2_o',\n",
       " 'ROP_c_2_o',\n",
       " 'ROST_c_2_o',\n",
       " 'RRC_c_2_o',\n",
       " 'RSG_c_2_o',\n",
       " 'RTN_c_2_o',\n",
       " 'SBUX_c_2_o',\n",
       " 'SCG_c_2_o',\n",
       " 'SCHW_c_2_o',\n",
       " 'SEE_c_2_o',\n",
       " 'SHW_c_2_o',\n",
       " 'SIG_c_2_o',\n",
       " 'SJM_c_2_o',\n",
       " 'SLG_c_2_o',\n",
       " 'SNPS_c_2_o',\n",
       " 'SO_c_2_o',\n",
       " 'SRCL_c_2_o',\n",
       " 'SRE_c_2_o',\n",
       " 'STI_c_2_o',\n",
       " 'STT_c_2_o',\n",
       " 'STX_c_2_o',\n",
       " 'SWK_c_2_o',\n",
       " 'SYMC_c_2_o',\n",
       " 'SYY_c_2_o',\n",
       " 'T_c_2_o',\n",
       " 'TEL_c_2_o',\n",
       " 'TGT_c_2_o',\n",
       " 'TJX_c_2_o',\n",
       " 'TMK_c_2_o',\n",
       " 'TMO_c_2_o',\n",
       " 'TROW_c_2_o',\n",
       " 'TRV_c_2_o',\n",
       " 'TSCO_c_2_o',\n",
       " 'TWX_c_2_o',\n",
       " 'TXN_c_2_o',\n",
       " 'TXT_c_2_o',\n",
       " 'UAA_c_2_o',\n",
       " 'UAL_c_2_o',\n",
       " 'UDR_c_2_o',\n",
       " 'UHS_c_2_o',\n",
       " 'ULTA_c_2_o',\n",
       " 'UNH_c_2_o',\n",
       " 'UNM_c_2_o',\n",
       " 'UNP_c_2_o',\n",
       " 'UPS_c_2_o',\n",
       " 'URI_c_2_o',\n",
       " 'USB_c_2_o',\n",
       " 'UTX_c_2_o',\n",
       " 'VAR_c_2_o',\n",
       " 'VFC_c_2_o',\n",
       " 'VIAB_c_2_o',\n",
       " 'VLO_c_2_o',\n",
       " 'VMC_c_2_o',\n",
       " 'VNO_c_2_o',\n",
       " 'VRSN_c_2_o',\n",
       " 'VRTX_c_2_o',\n",
       " 'VTR_c_2_o',\n",
       " 'WAT_c_2_o',\n",
       " 'WBA_c_2_o',\n",
       " 'WEC_c_2_o',\n",
       " 'WFC_c_2_o',\n",
       " 'WHR_c_2_o',\n",
       " 'WLTW_c_2_o',\n",
       " 'WM_c_2_o',\n",
       " 'WMB_c_2_o',\n",
       " 'WMT_c_2_o',\n",
       " 'WU_c_2_o',\n",
       " 'WY_c_2_o',\n",
       " 'WYN_c_2_o',\n",
       " 'WYNN_c_2_o',\n",
       " 'XEC_c_2_o',\n",
       " 'XEL_c_2_o',\n",
       " 'XL_c_2_o',\n",
       " 'XLNX_c_2_o',\n",
       " 'XOM_c_2_o',\n",
       " 'XRAY_c_2_o',\n",
       " 'XRX_c_2_o',\n",
       " 'ZBH_c_2_o',\n",
       " 'ZION_c_2_o',\n",
       " 'A_h_2_l',\n",
       " 'AAL_h_2_l',\n",
       " 'AAP_h_2_l',\n",
       " 'AAPL_h_2_l',\n",
       " 'ABC_h_2_l',\n",
       " 'ACN_h_2_l',\n",
       " 'ADBE_h_2_l',\n",
       " 'ADI_h_2_l',\n",
       " 'ADM_h_2_l',\n",
       " 'ADSK_h_2_l',\n",
       " 'AEE_h_2_l',\n",
       " 'AEP_h_2_l',\n",
       " 'AES_h_2_l',\n",
       " 'AET_h_2_l',\n",
       " 'AFL_h_2_l',\n",
       " 'AGN_h_2_l',\n",
       " 'AIG_h_2_l',\n",
       " 'AIV_h_2_l',\n",
       " 'AIZ_h_2_l',\n",
       " 'AJG_h_2_l',\n",
       " 'AKAM_h_2_l',\n",
       " 'ALB_h_2_l',\n",
       " 'ALK_h_2_l',\n",
       " 'ALL_h_2_l',\n",
       " 'ALXN_h_2_l',\n",
       " 'AMAT_h_2_l',\n",
       " 'AMD_h_2_l',\n",
       " 'AME_h_2_l',\n",
       " 'AMG_h_2_l',\n",
       " 'AMGN_h_2_l',\n",
       " 'AMP_h_2_l',\n",
       " 'AMT_h_2_l',\n",
       " 'ANSS_h_2_l',\n",
       " 'ANTM_h_2_l',\n",
       " 'AON_h_2_l',\n",
       " 'APA_h_2_l',\n",
       " 'APC_h_2_l',\n",
       " 'APD_h_2_l',\n",
       " 'APH_h_2_l',\n",
       " 'ARE_h_2_l',\n",
       " 'ARNC_h_2_l',\n",
       " 'ATVI_h_2_l',\n",
       " 'AVB_h_2_l',\n",
       " 'AVY_h_2_l',\n",
       " 'AYI_h_2_l',\n",
       " 'AZO_h_2_l',\n",
       " 'BA_h_2_l',\n",
       " 'BAX_h_2_l',\n",
       " 'BBT_h_2_l',\n",
       " 'BCR_h_2_l',\n",
       " 'BDX_h_2_l',\n",
       " 'BEN_h_2_l',\n",
       " 'BHGE_h_2_l',\n",
       " 'BIIB_h_2_l',\n",
       " 'BK_h_2_l',\n",
       " 'BLL_h_2_l',\n",
       " 'BMY_h_2_l',\n",
       " 'BWA_h_2_l',\n",
       " 'BXP_h_2_l',\n",
       " 'CA_h_2_l',\n",
       " 'CAH_h_2_l',\n",
       " 'CB_h_2_l',\n",
       " 'CBS_h_2_l',\n",
       " 'CCI_h_2_l',\n",
       " 'CDNS_h_2_l',\n",
       " 'CELG_h_2_l',\n",
       " 'CERN_h_2_l',\n",
       " 'CF_h_2_l',\n",
       " 'CHK_h_2_l',\n",
       " 'CHRW_h_2_l',\n",
       " 'CI_h_2_l',\n",
       " 'CL_h_2_l',\n",
       " 'CLX_h_2_l',\n",
       " 'CMA_h_2_l',\n",
       " 'CMCSA_h_2_l',\n",
       " 'CMG_h_2_l',\n",
       " 'CMS_h_2_l',\n",
       " 'CNC_h_2_l',\n",
       " 'CNP_h_2_l',\n",
       " 'COF_h_2_l',\n",
       " 'COG_h_2_l',\n",
       " 'COH_h_2_l',\n",
       " 'COL_h_2_l',\n",
       " 'COO_h_2_l',\n",
       " 'COST_h_2_l',\n",
       " 'CPB_h_2_l',\n",
       " 'CRM_h_2_l',\n",
       " 'CSCO_h_2_l',\n",
       " 'CSX_h_2_l',\n",
       " 'CTAS_h_2_l',\n",
       " 'CTL_h_2_l',\n",
       " 'CTSH_h_2_l',\n",
       " 'CTXS_h_2_l',\n",
       " 'CVS_h_2_l',\n",
       " 'CVX_h_2_l',\n",
       " 'D_h_2_l',\n",
       " 'DAL_h_2_l',\n",
       " 'DE_h_2_l',\n",
       " 'DFS_h_2_l',\n",
       " 'DGX_h_2_l',\n",
       " 'DHR_h_2_l',\n",
       " 'DISCA_h_2_l',\n",
       " 'DLR_h_2_l',\n",
       " 'DLTR_h_2_l',\n",
       " 'DOV_h_2_l',\n",
       " 'DRE_h_2_l',\n",
       " 'DRI_h_2_l',\n",
       " 'DUK_h_2_l',\n",
       " 'DVN_h_2_l',\n",
       " 'DWDP_h_2_l',\n",
       " 'DXC_h_2_l',\n",
       " 'EA_h_2_l',\n",
       " 'ECL_h_2_l',\n",
       " 'EFX_h_2_l',\n",
       " 'EL_h_2_l',\n",
       " 'EMN_h_2_l',\n",
       " 'EMR_h_2_l',\n",
       " 'EOG_h_2_l',\n",
       " 'EQIX_h_2_l',\n",
       " 'EQR_h_2_l',\n",
       " 'EQT_h_2_l',\n",
       " 'ES_h_2_l',\n",
       " 'ESS_h_2_l',\n",
       " 'ETFC_h_2_l',\n",
       " 'ETN_h_2_l',\n",
       " 'ETR_h_2_l',\n",
       " 'EW_h_2_l',\n",
       " 'EXC_h_2_l',\n",
       " 'EXPD_h_2_l',\n",
       " 'EXPE_h_2_l',\n",
       " 'EXR_h_2_l',\n",
       " 'F_h_2_l',\n",
       " 'FAST_h_2_l',\n",
       " 'FCX_h_2_l',\n",
       " 'FDX_h_2_l',\n",
       " 'FE_h_2_l',\n",
       " 'FFIV_h_2_l',\n",
       " 'FIS_h_2_l',\n",
       " 'FISV_h_2_l',\n",
       " 'FITB_h_2_l',\n",
       " 'FL_h_2_l',\n",
       " 'FLIR_h_2_l',\n",
       " 'FLR_h_2_l',\n",
       " 'FLS_h_2_l',\n",
       " 'FMC_h_2_l',\n",
       " 'FOX_h_2_l',\n",
       " 'FRT_h_2_l',\n",
       " 'FTI_h_2_l',\n",
       " 'GD_h_2_l',\n",
       " 'GE_h_2_l',\n",
       " 'GILD_h_2_l',\n",
       " 'GIS_h_2_l',\n",
       " 'GLW_h_2_l',\n",
       " 'GOOG_h_2_l',\n",
       " 'GOOGL_h_2_l',\n",
       " 'GPC_h_2_l',\n",
       " 'GPS_h_2_l',\n",
       " 'GRMN_h_2_l',\n",
       " 'GS_h_2_l',\n",
       " 'GT_h_2_l',\n",
       " 'HAL_h_2_l',\n",
       " 'HAS_h_2_l',\n",
       " 'HBAN_h_2_l',\n",
       " 'HBI_h_2_l',\n",
       " 'HCN_h_2_l',\n",
       " 'HCP_h_2_l',\n",
       " 'HES_h_2_l',\n",
       " 'HIG_h_2_l',\n",
       " 'HOLX_h_2_l',\n",
       " 'HON_h_2_l',\n",
       " 'HP_h_2_l',\n",
       " 'HRB_h_2_l',\n",
       " 'HRL_h_2_l',\n",
       " 'HRS_h_2_l',\n",
       " 'HSIC_h_2_l',\n",
       " 'HST_h_2_l',\n",
       " 'HSY_h_2_l',\n",
       " 'HUM_h_2_l',\n",
       " 'IBM_h_2_l',\n",
       " 'ICE_h_2_l',\n",
       " 'IDXX_h_2_l',\n",
       " 'IFF_h_2_l',\n",
       " 'ILMN_h_2_l',\n",
       " 'INCY_h_2_l',\n",
       " 'INTC_h_2_l',\n",
       " 'INTU_h_2_l',\n",
       " 'IP_h_2_l',\n",
       " 'IPG_h_2_l',\n",
       " 'IR_h_2_l',\n",
       " 'IRM_h_2_l',\n",
       " 'ISRG_h_2_l',\n",
       " 'IT_h_2_l',\n",
       " 'IVZ_h_2_l',\n",
       " 'JBHT_h_2_l',\n",
       " 'JCI_h_2_l',\n",
       " 'JEC_h_2_l',\n",
       " 'JNPR_h_2_l',\n",
       " 'JWN_h_2_l',\n",
       " 'KMB_h_2_l',\n",
       " 'KMX_h_2_l',\n",
       " 'KO_h_2_l',\n",
       " 'KR_h_2_l',\n",
       " 'KSU_h_2_l',\n",
       " 'L_h_2_l',\n",
       " 'LEN_h_2_l',\n",
       " 'LH_h_2_l',\n",
       " 'LKQ_h_2_l',\n",
       " 'LLY_h_2_l',\n",
       " 'LMT_h_2_l',\n",
       " 'LNT_h_2_l',\n",
       " 'LOW_h_2_l',\n",
       " 'LUK_h_2_l',\n",
       " 'LUV_h_2_l',\n",
       " 'M_h_2_l',\n",
       " 'MA_h_2_l',\n",
       " 'MAA_h_2_l',\n",
       " 'MAC_h_2_l',\n",
       " 'MAR_h_2_l',\n",
       " 'MAS_h_2_l',\n",
       " 'MAT_h_2_l',\n",
       " 'MCD_h_2_l',\n",
       " 'MCK_h_2_l',\n",
       " 'MDLZ_h_2_l',\n",
       " 'MDT_h_2_l',\n",
       " 'MET_h_2_l',\n",
       " 'MGM_h_2_l',\n",
       " 'MHK_h_2_l',\n",
       " 'MKC_h_2_l',\n",
       " 'MMC_h_2_l',\n",
       " 'MNST_h_2_l',\n",
       " 'MO_h_2_l',\n",
       " 'MOS_h_2_l',\n",
       " 'MRK_h_2_l',\n",
       " 'MRO_h_2_l',\n",
       " 'MS_h_2_l',\n",
       " 'MSFT_h_2_l',\n",
       " 'MSI_h_2_l',\n",
       " 'MTB_h_2_l',\n",
       " 'MU_h_2_l',\n",
       " 'MYL_h_2_l',\n",
       " 'NBL_h_2_l',\n",
       " 'NEE_h_2_l',\n",
       " 'NFLX_h_2_l',\n",
       " 'NI_h_2_l',\n",
       " 'NKE_h_2_l',\n",
       " 'NOC_h_2_l',\n",
       " 'NOV_h_2_l',\n",
       " 'NRG_h_2_l',\n",
       " 'NSC_h_2_l',\n",
       " 'NTAP_h_2_l',\n",
       " 'NTRS_h_2_l',\n",
       " 'NUE_h_2_l',\n",
       " 'NVDA_h_2_l',\n",
       " 'NWL_h_2_l',\n",
       " 'OKE_h_2_l',\n",
       " 'OMC_h_2_l',\n",
       " 'ORLY_h_2_l',\n",
       " 'OXY_h_2_l',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols\n",
    "input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InputDF = clean_and_flat[input_cols]#[:3900]\n",
    "TargetDF = clean_and_flat[target_cols]#[:3900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2267, 384)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs = TargetDF.corr()\n",
    "TargetDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Targets\n",
    "We now have an our inputs and targets, kind of. \n",
    "InputsDF has all the inputs we want to predict. Targets DF has the return of each stock each day. \n",
    "For starters, lets give a simpler target to predict than the reuturn of each stock, since we don't have much data. \n",
    "\n",
    "\n",
    "We're going to label the targets as either up (1) down (-1) or flat (0) days.\n",
    "The top chart shows what would happen if we bought 1 dollar of ewach stock each day\n",
    "The bottom chart shows what would happen if we longed the whole basket on (1) days, shorted it on down days (-1) and ignored it on  (0) days. \n",
    "You can see that this is a valuable target to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_stocks = len(TargetDF.columns)\n",
    "num_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2008-01-02    0.005537\n",
       "2008-01-03    0.027668\n",
       "2008-01-04   -0.001168\n",
       "2008-01-07    0.020450\n",
       "2008-01-08   -0.010201\n",
       "2008-01-09   -0.012981\n",
       "2008-01-10    0.015233\n",
       "2008-01-11   -0.010236\n",
       "2008-01-14    0.023431\n",
       "2008-01-15   -0.001856\n",
       "2008-01-16    0.027260\n",
       "2008-01-17    0.004273\n",
       "2008-01-18    0.003663\n",
       "2008-01-22   -0.028865\n",
       "2008-01-23   -0.009122\n",
       "2008-01-24    0.011444\n",
       "2008-01-25   -0.019774\n",
       "2008-01-28   -0.007806\n",
       "2008-01-29    0.006696\n",
       "2008-01-30   -0.018555\n",
       "2008-01-31   -0.022125\n",
       "2008-02-01    0.011211\n",
       "2008-02-04    0.028636\n",
       "2008-02-05    0.007408\n",
       "2008-02-06   -0.011387\n",
       "2008-02-07    0.004055\n",
       "2008-02-08   -0.004944\n",
       "2008-02-11   -0.006074\n",
       "2008-02-12   -0.012791\n",
       "2008-02-13    0.014493\n",
       "                ...   \n",
       "2016-11-17    0.002608\n",
       "2016-11-18   -0.008021\n",
       "2016-11-21   -0.002510\n",
       "2016-11-22   -0.002956\n",
       "2016-11-23   -0.003612\n",
       "2016-11-25    0.006032\n",
       "2016-11-28   -0.001053\n",
       "2016-11-29    0.000409\n",
       "2016-11-30    0.003930\n",
       "2016-12-01   -0.001595\n",
       "2016-12-02   -0.006931\n",
       "2016-12-05   -0.004346\n",
       "2016-12-06   -0.013319\n",
       "2016-12-07   -0.004166\n",
       "2016-12-08   -0.002854\n",
       "2016-12-09    0.003304\n",
       "2016-12-12   -0.004081\n",
       "2016-12-13    0.010794\n",
       "2016-12-14   -0.003416\n",
       "2016-12-15    0.002603\n",
       "2016-12-16   -0.001238\n",
       "2016-12-19   -0.004366\n",
       "2016-12-20    0.002425\n",
       "2016-12-21    0.003772\n",
       "2016-12-22   -0.002021\n",
       "2016-12-23   -0.003265\n",
       "2016-12-27    0.010648\n",
       "2016-12-28   -0.000502\n",
       "2016-12-29    0.003626\n",
       "2016-12-30    0.000000\n",
       "Length: 2267, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TotalReturn = ((1-exp(TargetDF)).sum(1))/num_stocks # If i put one dollar in each stock at the close, this is how much I'd get back\n",
    "TotalReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labeler(x):\n",
    "    if x>0.0029:\n",
    "        return 1\n",
    "    if x<-0.00462:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "      <th>class</th>\n",
       "      <th>multi_class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>0.005537</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>0.027668</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-0.001168</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>0.020450</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-08</th>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              return  class multi_class\n",
       "Date                                   \n",
       "2008-01-02  0.005537      1           8\n",
       "2008-01-03  0.027668      1          10\n",
       "2008-01-04 -0.001168      0           5\n",
       "2008-01-07  0.020450      1          10\n",
       "2008-01-08 -0.010201     -1           1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labeled = pd.DataFrame()\n",
    "Labeled['return'] = TotalReturn\n",
    "Labeled['class'] = TotalReturn.apply(labeler,1)\n",
    "Labeled['multi_class'] = pd.qcut(TotalReturn,11,labels=range(11))\n",
    "Labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.00121, 0.0072], (0.0072, 0.103], (-0.00303, 0.00121], (-0.117, -0.00855], (-0.00855, -0.00303]]\n",
       "Categories (5, interval[float64]): [(-0.117, -0.00855] < (-0.00855, -0.00303] < (-0.00303, 0.00121] < (0.00121, 0.0072] < (0.0072, 0.103]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(TotalReturn,5).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labeler_multi(x):\n",
    "    if x>0.0029:\n",
    "        return 1\n",
    "    if x<-0.00462:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    776\n",
       "-1    759\n",
       " 1    732\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labeled['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Labeled['act_return'] = Labeled['class'] * Labeled['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x116d8c2e8>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x117095978>], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEVCAYAAAAl9QikAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEeBWkTUX22QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116d7c780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Labeled[['return','act_return']].cumsum().plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = logreg.fit(InputDF[:-test_size],Labeled['multi_class'][:-test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(Labeled['multi_class'][-test_size:],res.predict(InputDF[-test_size:])))\n",
    "print(confusion_matrix(Labeled['multi_class'][-test_size:],res.predict(InputDF[-test_size:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Labeled['predicted_action'] = list(map(lambda x: -1 if x <5 else 0 if x==5 else 1,res.predict(InputDF)))\n",
    "print(confusion_matrix(Labeled['class'][-test_size:],Labeled['predicted_action'][-test_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Labeled['pred_return'] = Labeled['predicted_action'] * Labeled['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res = Labeled[-test_size:][['return','act_return','pred_return']].cumsum()\n",
    "Res[0] =0\n",
    "Res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a basic feed forward network\n",
    "Here I'll use the tensorflow contrib.learn to quickly train a feed forward network. More of a benchmark than something I plan on using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from  tensorflow.contrib.learn.python.learn.estimators.dnn  import DNNClassifier\n",
    "from tensorflow.contrib.layers import real_valued_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Labeled['tf_class'] = Labeled['multi_class']\n",
    "num_features = len(InputDF.columns)\n",
    "dropout=0.2\n",
    "hidden_1_size = 1000\n",
    "hidden_2_size = 250\n",
    "num_classes = Labeled.tf_class.nunique()\n",
    "NUM_EPOCHS=100\n",
    "BATCH_SIZE=50\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=600\n",
    "train = (InputDF[:-test_size].values,Labeled.tf_class[:-test_size].values)\n",
    "val = (InputDF[-test_size:].values,Labeled.tf_class[-test_size:].values)\n",
    "NUM_TRAIN_BATCHES = int(len(train[0])/BATCH_SIZE)\n",
    "NUM_VAL_BATCHES = int(len(val[1])/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2267"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(InputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        self.input_data = tf.placeholder(dtype=tf.float32,shape=[None,num_features])\n",
    "        self.target_data = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "        self.dropout_prob = tf.placeholder(dtype=tf.float32,shape=[])\n",
    "        with tf.variable_scope(\"ff\"):\n",
    "            droped_input = tf.nn.dropout(self.input_data,keep_prob=self.dropout_prob)\n",
    "            \n",
    "            layer_1 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=hidden_1_size,\n",
    "                inputs=droped_input,\n",
    "            )\n",
    "            layer_2 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=hidden_2_size,\n",
    "                inputs=layer_1,\n",
    "            )\n",
    "            self.logits = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=num_classes,\n",
    "                activation_fn =None,\n",
    "                inputs=layer_2,\n",
    "            )\n",
    "        with tf.variable_scope(\"loss\"):\n",
    "            \n",
    "            #self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(self.logits,self.target_data)\n",
    "            self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits,labels=self.target_data)\n",
    "            mask = (1-tf.sign(1-self.target_data)) #Don't give credit for flat days\n",
    "            mask = tf.cast(mask,tf.float32)\n",
    "            self.loss = tf.reduce_sum(self.losses)\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "          opt = tf.train.AdamOptimizer(lr)\n",
    "          gvs = opt.compute_gradients(self.loss)\n",
    "          self.train_op = opt.apply_gradients(gvs, global_step=global_step)\n",
    "        \n",
    "        with tf.name_scope(\"predictions\"):\n",
    "            self.probs = tf.nn.softmax(self.logits)\n",
    "            self.predictions = tf.argmax(self.probs, 1)\n",
    "            correct_pred = tf.cast(tf.equal(self.predictions, tf.cast(self.target_data,tf.int64)),tf.float64)\n",
    "            self.accuracy = tf.reduce_mean(correct_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step - 33 loss - 4206.620796203613 acc - 0.14\n",
      "step - 66 loss - 3619.7162704467773 acc - 0.24\n",
      "step - 99 loss - 3172.500198364258 acc - 0.4\n",
      "step - 132 loss - 2796.672504425049 acc - 0.42\n",
      "step - 165 loss - 2381.730888366699 acc - 0.56\n",
      "step - 198 loss - 2168.796760559082 acc - 0.66\n",
      "step - 231 loss - 1846.9875812530518 acc - 0.68\n",
      "step - 264 loss - 1550.8719501495361 acc - 0.76\n",
      "step - 297 loss - 1334.8128995895386 acc - 0.84\n",
      "step - 330 loss - 1157.4975700378418 acc - 0.86\n",
      "step - 363 loss - 929.8849601745605 acc - 0.9\n",
      "step - 396 loss - 755.9341883659363 acc - 0.96\n",
      "step - 429 loss - 590.8447506427765 acc - 0.96\n",
      "step - 462 loss - 504.1566376686096 acc - 0.98\n",
      "step - 495 loss - 427.7162718772888 acc - 0.98\n",
      "step - 528 loss - 362.2779076099396 acc - 0.96\n",
      "step - 561 loss - 311.27459847927094 acc - 0.98\n",
      "step - 594 loss - 288.3419305086136 acc - 0.98\n",
      "step - 627 loss - 257.74057257175446 acc - 0.94\n",
      "step - 660 loss - 257.8323961496353 acc - 0.96\n",
      "step - 693 loss - 239.55607843399048 acc - 0.84\n",
      "step - 726 loss - 223.49027562141418 acc - 0.92\n",
      "step - 759 loss - 286.9790314435959 acc - 0.98\n",
      "step - 792 loss - 271.90874433517456 acc - 0.92\n",
      "step - 825 loss - 257.14265155792236 acc - 0.9\n",
      "step - 858 loss - 200.8630119562149 acc - 0.98\n",
      "step - 891 loss - 165.23295390605927 acc - 0.98\n",
      "step - 924 loss - 111.09485214948654 acc - 0.96\n",
      "step - 957 loss - 88.77572560310364 acc - 1.0\n",
      "step - 990 loss - 68.39974737167358 acc - 1.0\n",
      "step - 1023 loss - 58.677659958601 acc - 1.0\n",
      "step - 1056 loss - 58.8388985991478 acc - 1.0\n",
      "step - 1089 loss - 49.73355495929718 acc - 1.0\n",
      "step - 1122 loss - 48.901323437690735 acc - 1.0\n",
      "step - 1155 loss - 44.21721389889717 acc - 1.0\n",
      "step - 1188 loss - 38.29227736592293 acc - 0.98\n",
      "step - 1221 loss - 37.88012045621872 acc - 1.0\n",
      "step - 1254 loss - 35.13560688495636 acc - 1.0\n",
      "step - 1287 loss - 34.313364297151566 acc - 1.0\n",
      "step - 1320 loss - 30.948039203882217 acc - 1.0\n",
      "step - 1353 loss - 29.387746766209602 acc - 1.0\n",
      "step - 1386 loss - 28.05059464275837 acc - 1.0\n",
      "step - 1419 loss - 25.31821647286415 acc - 1.0\n",
      "step - 1452 loss - 23.625344306230545 acc - 1.0\n",
      "step - 1485 loss - 22.922787874937057 acc - 1.0\n",
      "step - 1518 loss - 23.327466771006584 acc - 1.0\n",
      "step - 1551 loss - 21.776702523231506 acc - 1.0\n",
      "step - 1584 loss - 21.340306386351585 acc - 1.0\n",
      "step - 1617 loss - 18.88668519258499 acc - 1.0\n",
      "step - 1650 loss - 18.937460027635098 acc - 1.0\n",
      "step - 1683 loss - 18.246996819972992 acc - 1.0\n",
      "step - 1716 loss - 16.790382578969 acc - 1.0\n",
      "step - 1749 loss - 16.947044163942337 acc - 1.0\n",
      "step - 1782 loss - 16.80070550739765 acc - 1.0\n",
      "step - 1815 loss - 15.141464188694954 acc - 1.0\n",
      "step - 1848 loss - 15.10934992134571 acc - 1.0\n",
      "step - 1881 loss - 15.227134585380554 acc - 1.0\n",
      "step - 1914 loss - 14.259590677917004 acc - 1.0\n",
      "step - 1947 loss - 12.948409140110016 acc - 1.0\n",
      "step - 1980 loss - 13.328302003443241 acc - 1.0\n",
      "step - 2013 loss - 12.89231014251709 acc - 1.0\n",
      "step - 2046 loss - 13.398402854800224 acc - 1.0\n",
      "step - 2079 loss - 11.350594084709883 acc - 1.0\n",
      "step - 2112 loss - 10.288003779947758 acc - 1.0\n",
      "step - 2145 loss - 12.223294157534838 acc - 1.0\n",
      "step - 2178 loss - 9.94083347171545 acc - 1.0\n",
      "step - 2211 loss - 9.88257860392332 acc - 1.0\n",
      "step - 2244 loss - 9.898215472698212 acc - 1.0\n",
      "step - 2277 loss - 12.02157062292099 acc - 1.0\n",
      "step - 2310 loss - 37.473680421710014 acc - 1.0\n",
      "step - 2343 loss - 33.03633372485638 acc - 1.0\n",
      "step - 2376 loss - 213.75012239813805 acc - 1.0\n",
      "step - 2409 loss - 248.50753837823868 acc - 1.0\n",
      "step - 2442 loss - 266.3099020123482 acc - 1.0\n",
      "step - 2475 loss - 289.24518954753876 acc - 1.0\n",
      "step - 2508 loss - 504.42194271087646 acc - 1.0\n",
      "step - 2541 loss - 575.0075409412384 acc - 0.96\n",
      "step - 2574 loss - 575.5344195365906 acc - 1.0\n",
      "step - 2607 loss - 448.29215228557587 acc - 0.98\n",
      "step - 2640 loss - 125.74656122922897 acc - 0.98\n",
      "step - 2673 loss - 185.77337509393692 acc - 1.0\n",
      "step - 2706 loss - 321.00569862127304 acc - 0.5\n",
      "step - 2739 loss - 440.6634888648987 acc - 0.84\n",
      "step - 2772 loss - 982.5055620074272 acc - 0.72\n",
      "step - 2805 loss - 478.06424781680107 acc - 0.94\n",
      "step - 2838 loss - 280.4916445314884 acc - 1.0\n",
      "step - 2871 loss - 147.16805863380432 acc - 1.0\n",
      "step - 2904 loss - 84.47956907749176 acc - 1.0\n",
      "step - 2937 loss - 114.52124825119972 acc - 1.0\n",
      "step - 2970 loss - 36.24285224080086 acc - 1.0\n",
      "step - 3003 loss - 102.12637782096863 acc - 1.0\n",
      "step - 3036 loss - 69.91435799002647 acc - 1.0\n",
      "step - 3069 loss - 19.627169087529182 acc - 1.0\n",
      "step - 3102 loss - 11.518377497792244 acc - 1.0\n",
      "step - 3135 loss - 9.264129500836134 acc - 1.0\n",
      "step - 3168 loss - 7.699387826025486 acc - 1.0\n",
      "step - 3201 loss - 6.742537723854184 acc - 1.0\n",
      "step - 3234 loss - 7.887918632477522 acc - 1.0\n",
      "step - 3267 loss - 6.709431912750006 acc - 1.0\n",
      "step - 3300 loss - 6.04665063880384 acc - 1.0\n",
      "done training\n",
      "0.12\n",
      "0.04\n",
      "0.04\n",
      "0.2\n",
      "0.1\n",
      "0.1\n",
      "0.06\n",
      "0.1\n",
      "0.12\n",
      "0.08\n",
      "0.26\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model = Model()\n",
    "    input_ = train[0]\n",
    "    target = train[1]\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess.run([init])\n",
    "        epoch_loss =0\n",
    "        for e in range(NUM_EPOCHS):\n",
    "            if epoch_loss >0 and epoch_loss <1:\n",
    "                break\n",
    "            epoch_loss =0\n",
    "            for batch in range(0,NUM_TRAIN_BATCHES):\n",
    "                \n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:input_[start:end],\n",
    "                    model.target_data:target[start:end],\n",
    "                    model.dropout_prob:0.9\n",
    "                            }\n",
    "                \n",
    "                _,loss,acc = sess.run(\n",
    "                    [\n",
    "                        model.train_op,\n",
    "                        model.loss,\n",
    "                        model.accuracy,\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                epoch_loss+=loss\n",
    "            print('step - {0} loss - {1} acc - {2}'.format((1+batch+NUM_TRAIN_BATCHES*e),epoch_loss,acc))\n",
    "                \n",
    "        \n",
    "        print('done training')\n",
    "        final_preds =np.array([])\n",
    "        final_probs =None\n",
    "        for batch in range(0,NUM_VAL_BATCHES):\n",
    "            \n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:val[0][start:end],\n",
    "                    model.target_data:val[1][start:end],\n",
    "                    model.dropout_prob:1\n",
    "                            }\n",
    "                \n",
    "                acc,preds,probs = sess.run(\n",
    "                    [\n",
    "                        model.accuracy,\n",
    "                        model.predictions,\n",
    "                        model.probs\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                print(acc)\n",
    "                final_preds = np.concatenate((final_preds,preds),axis=0)\n",
    "                if final_probs is None:\n",
    "                    final_probs = probs\n",
    "                else:\n",
    "                    final_probs = np.concatenate((final_probs,probs),axis=0)\n",
    "        prediction_conf = final_probs[np.argmax(final_probs,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result = Labeled[-test_size:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result['nn_pred'] = final_preds\n",
    "Result['mod_nn_prod'] = list(map(lambda x: -1 if x <5 else 0 if x==5 else 1,final_preds))\n",
    "Result['nn_ret'] = Result.mod_nn_prod*Result['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Res = Result[-test_size:][['return','act_return','pred_return','nn_ret']].cumsum()\n",
    "Res = (1+Result[-test_size:][['return','act_return','nn_ret','pred_return']]).cumprod()\n",
    "Res[0] =0\n",
    "Res.plot(secondary_y='act_return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(Result['class'],Result['mod_nn_prod']))\n",
    "print(classification_report(Result['class'],Result['mod_nn_prod']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(Result['multi_class'],Result['nn_pred']))\n",
    "#sns.heatmap(cm.div(cm.sum(1)))\n",
    "Result[Result.multi_class==6]['return'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(Result['multi_class'],Result['nn_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result.hist(by='multi_class',column='return',sharex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Event - RNN\n",
    "In this section we'll make an rnn model that learns to take the past into account as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an rnn Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers.python.layers.initializers import xavier_initializer\n",
    "RNN_HIDDEN_SIZE=100\n",
    "FIRST_LAYER_SIZE=1000\n",
    "SECOND_LAYER_SIZE=250\n",
    "NUM_LAYERS=2\n",
    "BATCH_SIZE=50\n",
    "NUM_EPOCHS=200\n",
    "lr=0.0003\n",
    "NUM_TRAIN_BATCHES = int(len(train[0])/BATCH_SIZE)\n",
    "NUM_VAL_BATCHES = int(len(val[1])/BATCH_SIZE)\n",
    "ATTN_LENGTH=30\n",
    "beta=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel():\n",
    "    def __init__(self):\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        self.input_data = tf.placeholder(dtype=tf.float32,shape=[BATCH_SIZE,num_features])\n",
    "        self.target_data = tf.placeholder(dtype=tf.int32,shape=[BATCH_SIZE])\n",
    "        self.dropout_prob = tf.placeholder(dtype=tf.float32,shape=[])\n",
    "        \n",
    "        def makeGRUCells():\n",
    "            base_cell = tf.nn.rnn_cell.GRUCell(num_units=RNN_HIDDEN_SIZE,) \n",
    "            layered_cell = tf.nn.rnn_cell.MultiRNNCell([base_cell] * NUM_LAYERS,state_is_tuple=False) \n",
    "            attn_cell =tf.contrib.rnn.AttentionCellWrapper(cell=layered_cell,attn_length=ATTN_LENGTH,state_is_tuple=False)\n",
    "            return attn_cell\n",
    "        \n",
    "        self.gru_cell = makeGRUCells()\n",
    "        self.zero_state = self.gru_cell.zero_state(1, tf.float32)\n",
    "        \n",
    "        self.start_state = tf.placeholder(dtype=tf.float32,shape=[1,self.gru_cell.state_size])\n",
    "        \n",
    "        \n",
    "\n",
    "        with tf.variable_scope(\"ff\",initializer=xavier_initializer(uniform=False)):\n",
    "            droped_input = tf.nn.dropout(self.input_data,keep_prob=self.dropout_prob)\n",
    "            \n",
    "            layer_1 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=FIRST_LAYER_SIZE,\n",
    "                inputs=droped_input,\n",
    "                \n",
    "            )\n",
    "            layer_2 = tf.contrib.layers.fully_connected(\n",
    "                num_outputs=RNN_HIDDEN_SIZE,\n",
    "                inputs=layer_1,\n",
    "                \n",
    "            )\n",
    "            \n",
    "        \n",
    "        split_inputs = tf.reshape(droped_input,shape=[1,BATCH_SIZE,num_features],name=\"reshape_l1\") # Each item in the batch is a time step, iterate through them\n",
    "        split_inputs = tf.unpack(split_inputs,axis=1,name=\"unpack_l1\")\n",
    "        states =[]\n",
    "        outputs =[]\n",
    "        with tf.variable_scope(\"rnn\",initializer=xavier_initializer(uniform=False)) as scope:\n",
    "            state = self.start_state\n",
    "            for i, inp in enumerate(split_inputs):\n",
    "                if i >0:\n",
    "                    scope.reuse_variables()\n",
    "                \n",
    "                output, state = self.gru_cell(inp, state)\n",
    "                states.append(state)\n",
    "                outputs.append(output)\n",
    "        self.end_state = states[-1]\n",
    "        outputs = tf.pack(outputs,axis=1) # Pack them back into a single tensor\n",
    "        outputs = tf.reshape(outputs,shape=[BATCH_SIZE,RNN_HIDDEN_SIZE])\n",
    "        self.logits = tf.contrib.layers.fully_connected(\n",
    "            num_outputs=num_classes,\n",
    "            inputs=outputs,\n",
    "            activation_fn=None\n",
    "        )\n",
    "\n",
    "            \n",
    "        with tf.variable_scope(\"loss\"):\n",
    "            self.penalties =    tf.reduce_sum([beta*tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n",
    "\n",
    "            \n",
    "            self.losses = tf.nn.sparse_softmax_cross_entropy_with_logits(self.logits,self.target_data)\n",
    "            self.loss = tf.reduce_sum(self.losses + beta*self.penalties)\n",
    "        \n",
    "        with tf.name_scope(\"train_step\"):\n",
    "          opt = tf.train.AdamOptimizer(lr)\n",
    "          gvs = opt.compute_gradients(self.loss)\n",
    "          self.train_op = opt.apply_gradients(gvs, global_step=global_step)\n",
    "        \n",
    "        with tf.name_scope(\"predictions\"):\n",
    "            probs = tf.nn.softmax(self.logits)\n",
    "            self.predictions = tf.argmax(probs, 1)\n",
    "            correct_pred = tf.cast(tf.equal(self.predictions, tf.cast(self.target_data,tf.int64)),tf.float64)\n",
    "            self.accuracy = tf.reduce_mean(correct_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model = RNNModel()\n",
    "    input_ = train[0]\n",
    "    target = train[1]\n",
    "    with tf.Session() as sess:\n",
    "        init = tf.initialize_all_variables()\n",
    "        sess.run([init])\n",
    "        loss = 2000\n",
    "        \n",
    "        for e in range(NUM_EPOCHS):\n",
    "            state = sess.run(model.zero_state)\n",
    "            epoch_loss =0\n",
    "            for batch in range(0,NUM_TRAIN_BATCHES):\n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:input_[start:end],\n",
    "                    model.target_data:target[start:end],\n",
    "                    model.dropout_prob:0.5,\n",
    "                    model.start_state:state\n",
    "                            }\n",
    "                _,loss,acc,state = sess.run(\n",
    "                    [\n",
    "                        model.train_op,\n",
    "                        model.loss,\n",
    "                        model.accuracy,\n",
    "                        model.end_state\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                epoch_loss+=loss\n",
    "                \n",
    "            print('step - {0} loss - {1} acc - {2}'.format((e),epoch_loss,acc))\n",
    "        final_preds =np.array([])\n",
    "        for batch in range(0,NUM_VAL_BATCHES):\n",
    "                start = batch*BATCH_SIZE\n",
    "                end = start + BATCH_SIZE \n",
    "                feed = {\n",
    "                    model.input_data:val[0][start:end],\n",
    "                    model.target_data:val[1][start:end],\n",
    "                    model.dropout_prob:1,\n",
    "                    model.start_state:state\n",
    "                            }\n",
    "                acc,preds,state = sess.run(\n",
    "                    [\n",
    "                        model.accuracy,\n",
    "                        model.predictions,\n",
    "                        model.end_state\n",
    "                    ]\n",
    "                    ,feed_dict=feed\n",
    "                )\n",
    "                print(acc)\n",
    "                assert len(preds) == BATCH_SIZE\n",
    "                final_preds = np.concatenate((final_preds,preds),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result['rnn_pred'] = final_preds\n",
    "Result['mod_rnn_prod'] = list(map(lambda x: -1 if x <5 else 0 if x==5 else 1,final_preds))\n",
    "Result['rnn_ret'] = Result.mod_rnn_prod*Result['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(Result['multi_class'],Result['rnn_pred']))\n",
    "print(classification_report(Result['class'],Result['mod_rnn_prod']))\n",
    "print(confusion_matrix(Result['class'],Result['mod_rnn_prod']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(96/(96+82) + 94/(77+94))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res = (Result[-test_size:][['return','nn_ret','rnn_ret','pred_return']]).cumsum()\n",
    "Res[0] =0\n",
    "Res.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res.columns =['Market Baseline','Simple Neural Newtwork','My Algo','Logistic Regression (simple ML)','Do Nothing(0)']\n",
    "Res.plot(figsize=(20,10),title=\"Performance of MarketVectors algo over 27 months compared with baselines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res.columns\n",
    "Res.columns =['baseline','logistic_regression','feed_forward_net','rnn_net','do_nothing']\n",
    "Res.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.rnn_cell import BasicLSTMCell, GRUCell, MultiRNNCell, DropoutWrapper\n",
    "cell = tf.nn.rnn_cell.GRUCell(num_units=RNN_HIDDEN_SIZE)\n",
    "cell = MultiRNNCell(cells=[cell]*NUM_LAYERS,state_is_tuple=True)\n",
    "attn_cell =tf.contrib.rnn.AttentionCellWrapper(cell=cell,attn_length=ATTN_LENGTH,state_is_tuple=True)\n",
    "print(attn_cell.zero_state(batch_size=1,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.start_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ([1,2,3,4],())\n",
    "y = sum([1,2,3],())\n",
    "type(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Labeled.hist(column='return',by='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = sns.FacetGrid(Result, row=\"class\", col=\"rnn_pred\", margin_titles=True)\n",
    "g.map(sns.distplot, \"return\",);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result.hist(by=['class','nn_pred'],column='return',sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result['zreturn'] = zscore(Result['return'])\n",
    "Result['day'] = Result.index.dayofweek\n",
    "sns.lmplot(data=Result,y='zreturn',x='nn_prediction_conf',hue='day',col='class',row='nn_pred',fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Result.index.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Res.rnn_ret.mean()/Res.rnn_ret.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
